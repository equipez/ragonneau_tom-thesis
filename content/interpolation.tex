%% contents/interpolation.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{Interpolation models for \glsfmtlong{dfo}}

\section{Introduction and motivation}

As mentioned in \cref{ch:introduction}, model-based \gls{dfo} methods necessitate to approximate locally the functions involved in optimization problems by simple functions, referred to as \emph{models} or \emph{surrogates}.
These models are used to construct subproblems that are in turn approximately minimized.
Examples of such functions commonly used in the literature are polynomials and \glspl{rbf}~\cite{Powell_2004a}.
In this thesis, we focus on linear and quadratic polynomial models, i.e., on polynomials of degree at most one and two, respectively.

Let~$\lpoly$ and~$\qpoly$ denote the spaces of linear and quadratic polynomials on~$\R^n$, respectively.
In a \gls{dfo} context, models from~$\lpoly$ or~$\qpoly$ are built for a real-valued function~$\obj$ without using derivatives.
This can be done by interpolation schemes based on function values.
More specifically, given a finite set of points~$\xpt \subseteq \R^n$, we construct a model~$\objm$ that interpolates the function~$\obj$ on~$\xpt$, i.e.,
\begin{equation}
    \label{eq:interpolation-conditions}
    \objm(y) = \obj(y), \quad \text{for~$y \in \xpt$}.
\end{equation}

The conditions~\cref{eq:interpolation-conditions} may be inconsistent.
In such a case, models can be built using regression schemes.
For example, a least-square regression model~$\objm$ minimizes
\begin{equation*}
    \sum_{\mathclap{y \in \xpt}} [\obj(y) - \objm(y)]^2.
\end{equation*}
Although there are successful methods that use regression models (see, e.g.,~\cite{Billups_Larson_Graf_2013,Conn_Scheinberg_Vicente_2008b}), the \gls{dfo} methods we present and develop in this thesis use interpolation models and ensure that the interpolation conditions are consistent and well-conditioned (see \cref{ch:pdfo,ch:cobyqa-introduction}).

It is also possible to use polynomials of degree higher than two.
However, we do not consider such models in this thesis due to the following observations.
\begin{enumerate}
    \item As shown in~\cite[thm.~2.5]{Wendland_2005}, the space of polynomials on~$\R^n$ of degree at most~$k$ has a dimension of
    \begin{equation*}
        \binom{n + k}{n} = \frac{1}{k!} \prod_{i = 1}^k (n + i) \ge \frac{n^k}{k!}.
    \end{equation*}
    Therefore, to determine a model from this space merely by the interpolation conditions~\cref{eq:interpolation-conditions}, we need in general~$\bigo(n^k)$ function values.
    This amount is unacceptable in a \gls{dfo} context unless~$k$ is small.
    It is possible to reduce this number with underdetermined interpolation, which is used by several optimization methods for~$k \le 2$ (see \cref{sec:underdetermined-interpolation}), including the method \gls{cobyqa} developed in this thesis (see \cref{ch:cobyqa-introduction}).
    Using underdetermined interpolation models with~$k \ge 3$ is out of the scope of this thesis, although it is an interesting research direction.
    \item The \gls{dfo} methods need to solve approximately subproblems (e.g., trust-region subproblems) built upon these models.
    Sophisticated models usually lead to complicated subproblems to solve.
    On the other hand, even with models that are not quadratic, practical algorithms normally solve the subproblems based on first- or second-order approximations of the models, e.g., calculate the approximate Cauchy point discussed in~\cite[\S~6.3.3]{Conn_Gould_Toint_2000}.
    Therefore, building polynomial models of degree higher than two may not be necessary.
\end{enumerate}

Although we do not study \gls{rbf} models, we mention that there also exist many \gls{dfo} methods based on these models.
Examples of such methods include \gls{orbit}~\cite{Wild_Regis_Shoemaker_2008}, \gls{conorbit}~\cite{Regis_Wild_2017}, and \gls{boosters}~\cite{Oeuvray_Bierlaire_2009}.

\section{Elementary concepts of multivariate interpolation}
\label{sec:multivariate-interpolation}

Before studying properties of multivariate interpolation, we must introduce the following notion of poisedness, which defines uniquely interpolants.

\begin{definition}[Poisedness]
    The set~$\xpt$ is \emph{poised} if the interpolation system~\cref{eq:interpolation-conditions} is consistent and has a unique solution for a given space in which~$\objm$ must lie.
\end{definition}

Let of first consider the problem of finding a linear model~$\objm \in \lpoly$ satisfying the interpolation system~\cref{eq:interpolation-conditions} whenever~$\card \xpt = \dim \lpoly = n + 1$.
In the natural basis of~$\lpoly$, the system~\cref{eq:interpolation-conditions} can be reformulated as
\begin{equation}
    \label{eq:linear-interpolation-conditions}
    \alpha_0 + \sum_{i = 1}^n \alpha_i y_i = \obj(y), \quad \text{for~$y \in \xpt$},
\end{equation}
where~$y_i$ denotes the~$i$th component of~$y \in \xpt$, and where~$\alpha_i \in \R$ for~$i \in \set{0, 1, \dots, n}$.
If~$\xpt$ is poised for linear interpolation, given~$\set{\alpha_0^{\ast}, \alpha_1^{\ast}, \dots, \alpha_n^{\ast}}$ the unique solution to the system~\cref{eq:linear-interpolation-conditions}, the linear model~$\objm$ is defined for~$x \in \R^n$ by
\begin{equation*}
    \objm(x) = \alpha_0^{\ast} + \sum_{i = 1}^n \alpha_i^{\ast} x_i,
\end{equation*}
and the vector~$\nabla \objm \equiv (\alpha_i^{\ast})_{i = 1, 2, \dots, n}$ is referred to as the \emph{simplex gradient} of~$\obj$ for the interpolation set~$\xpt$.
Such models are used for instance by \gls{cobyla}~\cite{Powell_1994}, a \gls{dfo} method for nonlinearly-constrained optimization detailed in \cref{subsec:cobyla}.

The problem of finding a quadratic model~$\objm \in \qpoly$ satisfying the interpolation system~\cref{eq:interpolation-conditions} whenever~$\card \xpt = \dim \qpoly = (n + 1)(n + 2) / 2$ is very similar.
Unlike linear model, quadratic models capture curvature information of the function~$\obj$, and are hence more precise.
Most recent model-based \gls{dfo} methods based on polynomial models use in fact quadratic models.
This is the case for instance for \gls{uobyqa}~\cite{Powell_2002}, a \gls{dfo} method for unconstrained optimization detailed in \cref{subsec:uobyqa}, which use the quadratic interpolation models mentioned above.
The new method we introduce in \cref{ch:cobyqa-introduction} also uses quadratic models, described in \cref{subsec:symmetric-broyden-updates}.
Therefore, we focus further considerations in this chapter on quadratic models.

\section{Overview of the Lagrange polynomials}
\label{sec:lagrange-polynomials}

For simplicity, we present in this section the Lagrange quadratic polynomials only.
Note that the theory presented below can be generalized to polynomials of any degree.

\begin{definition}[Lagrange quadratic polynomials]
    \label{def:lagrange-polynomials}
    Given a poised interpolation set~$\xpt \subseteq \R^n$ of~$(n + 1)(n + 2) / 2$ points, the Lagrange polynomial~$\lagp[y] \in \qpoly$ for~$y \in \xpt$ is the unique quadratic polynomial satisfying~$\lagp[y](y) = 1$ and
    \begin{equation*}
        \lagp[y](x) = 0, \quad \text{for~$x \in \xpt \setminus \set{y}$}.
    \end{equation*}
\end{definition}

We note that \cref{def:lagrange-polynomials} is well-defined, because the poisedness of the interpolation ensures the existence and the uniqueness of the Lagrange polynomials.
Moreover, as decribed by \cref{thm:lagrange-polynomials-basis}, the interpolant~$\objm$ can be formulated as a linear combinaison of the Lagrange polynomials, where the coefficients of the linear combinaison are exactly the values of~$\obj$ at the interpolation points.

\begin{theorem}
    \label{thm:lagrange-polynomials-basis}
    Given a poised interpolation set~$\xpt \subseteq \R^n$ of~$(n + 1)(n + 2) / 2$ points, the Lagrange polynomials~$\set{\lagp[y]}_{y \in \xpt}$ form a basis of~$\qpoly$.
    Moreover, the quadratic interpolant~$\objm$ of~$\obj$ on~$\xpt$ is given for any~$x \in \R^n$ by
    \begin{equation*}
        \objm(x) = \sum_{y \in \xpt} \obj(y) \lagp[y](x).
    \end{equation*}
\end{theorem}

In the context of \gls{dfo}, one of the most important application of the Lagrange polynomials is to measure the well-poisedness of the interpolation set~$\xpt$.
More specifically, \citeauthor{Ciarlet_Raviart_1972}~\cite{Ciarlet_Raviart_1972} showed that
\begin{equation*}
    \sup_{x \in \conv(\xpt)} \abs{\obj(x) - \objm(x)} \le \frac{\nu}{6} \sum_{y \in \xpt} \abs{\lagp[y](x)} \norm{x - y}^3,
\end{equation*}
whenever~$\obj$ is thrice differentiable in~$\conv(\xpt)$, where~$\conv(\xpt)$ denotes the convex hull of~$\xpt$, and where~$\nu$ is an upper bound on the absolute value of the third-order directional derivatives of~$\obj$ in~$\conv(\xpt)$.
Let~$\diam(\xpt)$ be the diameter of~$\xpt$, that is
\begin{equation*}
    \diam(\xpt) \eqdef \max_{x, y \in \xpt} \norm{x - y}.
\end{equation*}
We then clearly have
\begin{equation*}
    \sup_{x \in \conv(\xpt)} \abs{\obj(x) - \objm(x)} \le \frac{\nu}{12} (n + 1) (n + 2) \Lambda \diam(\xpt)^3,
\end{equation*}
where~$\Lambda$ is intimately related to the Lebesgue constant of~$\xpt$, and is defined by
\begin{equation*}
    \Lambda \eqdef \max_{y \in \xpt} \max_{x \in \conv(\xpt)} \abs{\lagp[y](x)}.
\end{equation*}
In some sense,~$\Lambda$ measures, therefore, the well-poisedness of the interpolation set~$\xpt$.
More details on this observation is given in \cref{sec:poisedness}.

\section{Poisedness of interpolation sets}
\label{sec:poisedness}

As before, the theory we develop in this section assumes that~$\objm \in \qpoly$.
It may be, however, generalized to any space of polynomials.

\subsection{Measuring the well poisedness of interpolation sets}

\begin{definition}[$\Lambda$-poisedness]
    A poised interpolation set~$\xpt \subseteq \R^n$ is said to be~$\Lambda$-poised in a compact set~$\mathcal{C} \subseteq \R^n$, for some~$\Lambda > 0$, if
    \begin{equation*}
        \Lambda \ge \max_{y \in \xpt} \max_{x \in \mathcal{C}} \abs{\lagp[y](x)}.
    \end{equation*}
\end{definition}

As we discussed before,~$\Lambda$ measures the quality of the interpolation set.

\begin{itemize}
    \item Definition of the~$\Lambda$-poisedness.
    \item The~$\Lambda$-poisedness measures the quality of the interpolation set.
    \item In practice we do not use it.
\end{itemize}

\subsection{Relationship with the conditioning of the interpolation system}

\begin{itemize}
    \item We consider here only the natural basis.
    \item The condition number is bounded by something that depends on~$\Lambda$.
\end{itemize}

\section{Underdetermined interpolation systems}
\label{sec:underdetermined-interpolation}

\begin{itemize}
    \item We focus on quadratic polynomials.
    \item Building a quadratic interpolation model necessitates~$\mathcal{O}(n^2)$ function evaluations.
    \item We want to reduce this number to~$\mathcal{O}(n)$.
    \item Freedom is bequeathed by minimizing a functional that reflects the regularity of the models.
    \item Two examples are given hereafter.
    \item The new method we introduce in \cref{ch:cobyqa-introduction} also uses quadratic models obtained by underdetermined interpolation.
\end{itemize}

\subsection{Least Frobenius norm quadratic models}

\begin{itemize}
    \item Factorization of the symmetric Broyden matrix.
    \item Updating the symmetric Broyden matrix.
    \item Decompositions of the Hessian matrices of the quadratic models.
    \item \gls{mnh}~\cite{Wild_2008}
\end{itemize}

\subsection{Quadratic models based on symmetric Broyden updates}
\label{subsec:symmetric-broyden-updates}

\begin{itemize}
    \item Explain the name.
    \item \gls{newuoa}~\cite{Powell_2006}
\end{itemize}

\section{An optimal number of interpolation points}

For~$1 \le i \le 2n + 1$ and some~$\delta > 0$, let~$y^i \in \R^n$ be the vector
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & 0,                        && \quad \text{if~$i = 1$,}\\
    & \delta e_{i - 1},         && \quad \text{if~$2 \le i \le n + 1$, and}\\
    & -\delta e_{i - n - 1},    && \quad \text{otherwise,}
\end{empheq}
where~$e_i \in \R^n$ denotes the~$i$th standard coordinate vector.
We define the interpolation sets~$\xpt[0, m] \subseteq \R$ for~$n + 2 \le m \le 2n + 1$ by
\begin{equation*}
    \xpt[0, m] \eqdef \set{y^i}_{i = 1, 2, \dots, m}.
\end{equation*}
Further, we denote by~$\ball[p](\xpt[0, m])$ the smallest~$\ell_p$-norm ball containing~$\xpt[0, m]$, for~$p \ge 1$.
Note that we allow~$p = \infty$.
We remark that
\begin{equation*}
    \ball[p](\xpt[0, m]) \equiv \set{x \in \R^n : \norm{x}_p \le \delta}.
\end{equation*}
Throughout this section, we denote by~$\lagp[i]$ the Lagrange function~$\lagp[y^i]$.

\begin{lemma}
    The minimum-norm Lagrange function associated with the above-defined interpolation are defined for~$x \in \R^n$ by
    \begin{empheq}[left={\lagp[i](x) = \empheqlbrace}]{alignat*=2}
        & 1 - \delta^{-2} \sum_{i = 1}^{m - n - 1} x_i^2 - \delta^{-1} \sum_{i = m - n}^{n} x_i,    && \quad \text{if~$i = 1$,}\\
        & (\sqrt{2}\delta)^{-2} x_{i - 1}^2 + (2\delta)^{-1} x_{i - 1},                             && \quad \text{if~$2 \le i \le m - n$,}\\
        & \delta^{-1} x_{i - 1},                                                                    && \quad \text{if~$m - n + 1 \le i \le n + 1$, and}\\
        & (\sqrt{2}\delta)^{-2} x_{i - n - 1}^2 - (2\delta)^{-1} x_{i - n - 1}.                     && \quad \text{otherwise.}
    \end{empheq}
\end{lemma}

\begin{proof}
    To do.
\end{proof}

\begin{theorem}
    \label{thm:lambda-poisedness-initial}
    For any~$n + 2 \le m \le 2n + 1$ and any~$p \in [1, \infty)$, the interpolation set~$\xpt[0, m]$ is~$\Lambda$-poised in~$\ball[p](\xpt[0, m])$ in the minimum-norm sense, with
    \begin{equation*}
        1 + (2n + 1 - m)^{\frac{p - 1}{p}} \le \Lambda \le n.
    \end{equation*}
\end{theorem}

We take the convention~$0^0 = 0$ in \cref{thm:lambda-poisedness-initial}.

\begin{proof}
    To do.
\end{proof}

\begin{proposition}
    For any~$n + 2 \le m \le 2n + 1$, the interpolation set~$\xpt[0, m]$ is~$\Lambda$-poised in~$\ball[1](\xpt[0, m])$ in the minimum-norm sense, with
    \begin{empheq}[left={\Lambda = \empheqlbrace}]{alignat*=2}
        & 2 && \quad \text{if~$n + 2 \le m \le 2n$, and}\\
        & 1 && \quad \text{otherwise.}
    \end{empheq}
\end{proposition}

\begin{proof}
    To do.
\end{proof}

\begin{proposition}
    For any~$n + 2 \le m \le 2n + 1$, the interpolation set~$\xpt[0, m]$ is~$\Lambda$-poised in~$\ball[2](\xpt[0, m])$ in the minimum-norm sense, with
    \begin{equation*}
        \Lambda = 1 + \sqrt{2n + 1 - m}.
    \end{equation*}
\end{proposition}

\begin{proof}
    To do.
\end{proof}

\begin{proposition}
    For any~$n + 2 \le m \le 2n + 1$, the interpolation set~$\xpt[0, m]$ is~$\Lambda$-poised in~$\ball[\infty](\xpt[0, m])$ in the minimum-norm sense, with
    \begin{empheq}[left={\Lambda = \empheqlbrace}]{alignat*=2}
        & n     && \quad \text{if~$m = n + 2$, and}\\
        & n - 1 && \quad \text{otherwise.}
    \end{empheq}
\end{proposition}

\begin{proof}
    To do.
\end{proof}

\begin{proposition}
    For any~$p \in [3, \infty)$, the interpolation set~$\xpt[0, 2n + 1]$ is~$\Lambda$-poised in~$\ball[p](\xpt[0, 2n + 1])$ in the minimum-norm sense, with
    \begin{equation*}
        \Lambda = \max \set[\big]{1, n^{\frac{p - 2}{p}} - 1}.
    \end{equation*}
\end{proposition}

\begin{proof}
    To do.
\end{proof}

% \begin{proof}
%     For simplicity, we denote in this proof~$\lagp[i]$ the polynomial~$\lagp[y^i]$ for~$1 \le i \le m$.
%     \begin{enumerate}
%         \item If~$n + 2 \le m \le 2n + 1$.
%         \begin{empheq}[left={\lagp[i](x) = \empheqlbrace}]{alignat*=2}
%             & 1 - \frac{1}{\delta^2} \sum_{i = 1}^{m - n - 1} x_i^2 - \frac{1}{\delta} \sum_{i = m - n}^{n} x_i,    && \quad \text{if~$i = 1$,}\\
%             & \frac{x_{i - 1}^2}{2\delta^2} + \frac{x_{i - 1}}{2\delta},                                            && \quad \text{if~$2 \le i \le m - n$,}\\
%             & \frac{x_{i - 1}}{\delta},                                                                             && \quad \text{if~$m - n + 1 \le i \le n + 1$, and}\\
%             & \frac{x_{i - n - 1}^2}{2\delta^2} - \frac{x_{i - n - 1}}{2\delta},                                    && \quad \text{otherwise.}\\
%         \end{empheq}
%         Note that~$\ball[p](\xpt[0, m]) = \set{x \in \R^n : \norm{x}_p \le \delta}$ for any~$p \in [1, \infty]$.
%         Therefore,
%         \begin{empheq}[left={\max\limits_{x \in \ball[1](\xpt[0, m])} \abs{\lagp[i](x)} = \empheqlbrace}]{alignat*=2}
%             & 2,    && \quad \text{if~$i = 1$ and~$n + 2 \le m \le 2n$,}\\
%             & 1,    && \quad \text{otherwise.}
%         \end{empheq}
%         Moreover
%         \begin{empheq}[left={\max\limits_{x \in \ball[2](\xpt[0, m])} \abs{\lagp[i](x)} = \empheqlbrace}]{alignat*=2}
%             & 1 + \sqrt{2n + 1 - m},    && \quad \text{if~$i = 1$, and}\\
%             & 1,                        && \quad \text{otherwise.}
%         \end{empheq}
%         Moreover,
%         \begin{empheq}[left={\max\limits_{x \in \ball[\infty](\xpt[0, m])} \abs{\lagp[i](x)} = \empheqlbrace}]{alignat*=2}
%             & n - 1,    && \quad \text{if~$i = 1$ and~$n + 3 \le m \le 2n + 1$,}\\
%             & n,        && \quad \text{if~$i = 1$ and~$m = n + 2$,}\\
%             & 1,        && \quad \text{otherwise.}
%         \end{empheq}
%     \end{enumerate}
% \end{proof}
