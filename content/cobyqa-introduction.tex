%% contents/cobyqa-introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ a new \glsfmtlong{dfo} method}
\label{ch:cobyqa-introduction}

\section{Statement of the problem}

In this chapter, we introduce a new model-based \gls{dfo} method for solving nonlinearly-constrained problems of the form
\begin{subequations}
    \label{eq:problem-cobyqa}
    \begin{align}
        \min        & \quad \obj(\iter) \label{eq:problem-cobyqa-obj}\\
        \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub, \label{eq:problem-cobyqa-ub}\\
                    & \quad \con{i}(\iter) = 0, ~ i \in \ieq, \label{eq:problem-cobyqa-eq}\\
                    & \quad \xl \le x \le \xu, \label{eq:problem-cobyqa-bd}\\
                    & \quad \iter \in \R^n, \nonumber
    \end{align}
\end{subequations}
where~$\obj$ and~$\con{i}$ represent the objective and constraint functions, with~$i \in \iub \cup \ieq$ and the sets of indices~$\iub$ and~$\ieq$ being finite and disjoint, but possibly empty. 
The lower bounds~$\xl \in (\R \cup \set{-\infty})^n$ and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl < \xu$.

We will develop a derivative-free trust-region \gls{sqp} method for solving the problem~\cref{eq:problem-cobyqa}.
The method, named~\gls{cobyqa} after \emph{\glsdesc{cobyqa}}, does not use derivatives of the objective function and the nonlinear constraint functions, but models them using underdetermined interpolation based on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).
This chapter presents the framework of the method, while the subproblems and the Python implementation will be discussed in \cref{ch:cobyqa-subproblems,ch:cobyqa-implementation}, respectively.


\section{Outline of the \glsfmttext{cobyqa} method}

\subsection{Management of bound and linear constraints}
\label{subsec:bound-constraints}

The implementation of \gls{cobyqa} accepts three types of constraints, namely bound constraints, linear constraints, and nonlinear constraints.
From a theoretical standpoint, problems written in the form~\cref{eq:problem-cobyqa-sqp} may have bound and linear constraints included in some of the constraints~$\con{i}$, with~$i \in \iub \cup \ieq$.
However, it is crucial that the implementation of a solver handles these types of constraints separately.

First of all, note that in the general form of nonlinearly-constrained problems~\cref{eq:problem-cobyqa}, we did not include the bound constraints~\cref{eq:problem-cobyqa-bd} in the inequality constraints~\cref{eq:problem-cobyqa-ub}.
This is because they often represent inalienable physical or theoretical restrictions.
In other words, in many applications, the objective function~\cref{eq:problem-cobyqa-obj} is not defined if the bounds constraints~\cref{eq:problem-cobyqa-bd} are violated.
For instance, the tuning of nonlinear optimization methods (see \cref{subsec:tuning-nonlinear-optimization-methods})  involves bounds that cannot be violated, as the optimizationmethods that are tuned may not be defined otherwise.
Very similar observations can be made on hyperparameter tuning in machine learning (see \cref{subsec:machine-learning}).
For this reason, every point that \gls{cobyqa} encounters always respects these bounds, as is also the case for the \gls{bobyqa} method, presented in \cref{subsec:newuoa-bobyqa-lincoa}.
When establishing the problem~\cref{eq:problem-cobyqa}, we assumed that~$\xl < \xu$.
Note that this requirement is weak, as otherwise, the problem~\cref{eq:problem-cobyqa} would be either infeasible, or admit fix variables.
Thus, note also that they are very simple constraints.
It is, for example, trivial to check whether a point is feasible with respect to the bound constraints~\cref{eq:problem-cobyqa-bd}, and easy to project any point onto the bound constraints.
This is another reason why \gls{cobyqa} handles them separately.

The linear constraints are usually much less restrictive.
The objective function is often well-defined even at points that are infeasible with respect to the linear constraints.
Therefore, we do not enforce \gls{cobyqa} to always respect the linear constraints.
However, when evaluating a model~$\conm[k]{i}$ of a linear constraint~$\con{i}$, we enforce~$\nabla \conm[k]{i} \equiv \nabla \con{i}$ and~$\nabla^2 \conm[k]{i} \equiv 0$, so that~$\conm[k]{i} \equiv \con{i}$.
This reduces the computational complexity of evaluating all the models, and it also suppresses all damages that could be generated by computer rounding errors.

\subsection{Interpolation-based quadratic models}
\label{subsec:cobyqa-models}

\begin{itemize}
    \item What is the initial interpolation set?
    \item How is this interpolation set updated?
    \item Approximations of linear function are exact (theorem).
\end{itemize}

\subsection{Merit functions and penalty coefficients}
\label{subsec:cobyqa-merit-function}

\begin{itemize}
    \item What is a merit function?
    \item Examples of merit functions (smooth, exact nonsmooth, augmented Lagrangian).
    \item We choose the~$\ell_2$-merit function (exact nonsmooth).
    \item The modeled merit function we choose is not directly the Taylor approximation.
    \item The modeled merit function must ensure a crucial decrease property (holds because of what follows).
    \item The best point so far considered by \gls{cobyqa} is the one with the least merit value.
    \item What is the trust-region ratio?
    \item \Cite[Thm.~14.5.1]{Conn_Gould_Toint_2000} provides a lower bound on the penalty coefficient.
    \item Detail the algorithm for increasing the penalty parameter.
    \item We decrease the penalty parameter as in~\cite{Powell_1994} (detail the modification made for the equality constraints).
\end{itemize}

\subsection{Geometry of the interpolation set}

\subsection{Estimation of the Lagrange multipliers}

\subsection{Maratos effect and \glsfmtlong{soc}}

\subsection{Summary of the method}
