%% contents/cobyqa-introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ a new \glsfmtlong{dfo} method}
\label{ch:cobyqa-introduction}

\section{Statement of the problem}

In this chapter, we introduce a new model-based \gls{dfo} method for solving nonlinearly-constrained problems of the form
\begin{subequations}
    \label{eq:problem-cobyqa}
    \begin{align}
        \min        & \quad \obj(\iter) \label{eq:problem-cobyqa-obj}\\
        \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub, \label{eq:problem-cobyqa-ub}\\
                    & \quad \con{i}(\iter) = 0, ~ i \in \ieq, \label{eq:problem-cobyqa-eq}\\
                    & \quad \xl \le x \le \xu, \label{eq:problem-cobyqa-bd}\\
                    & \quad \iter \in \R^n, \nonumber
    \end{align}
\end{subequations}
where~$\obj$ and~$\con{i}$ represent the objective and constraint functions, with~$i \in \iub \cup \ieq$ and the sets of indices~$\iub$ and~$\ieq$ being finite and disjoint, but possibly empty. 
The lower bounds~$\xl \in (\R \cup \set{-\infty})^n$ and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl < \xu$.
Note that the bound constraints~\cref{eq:problem-cobyqa-bd} are not included in the inequality constraints~\cref{eq:problem-cobyqa-ub}, because they will be handled separately, as detailed in \cref{sec:simple-constraints}.

We will develop a derivative-free trust-region \gls{sqp} method for the problem~\cref{eq:problem-cobyqa}.
The method, named~\gls{cobyqa} after \emph{\glsdesc{cobyqa}}, does not use derivatives of the objective function or the nonlinear constraint functions, but models them using underdetermined interpolation based on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).
This chapter presents the framework of the method, while the subproblems and the Python implementation will be discussed in \cref{ch:cobyqa-subproblems,ch:cobyqa-implementation}, respectively.

\section{The derivative-free trust-region \glsfmtshort{sqp} method}

We presented in \cref{ch:sqp} the basic trust-region \gls{sqp} method.
We now adapt this framework to derivative-free settings.

\subsection{Interpolation-based quadratic models}
\label{subsec:interpolation-based-quadratic-models}

Recall that the basic trust-region \gls{sqp} method presented in \cref{alg:trust-region-sqp} models the objective and constraint functions based on their gradients and Hessian matrices.
Since we do not have access to such information, we use interpolation-based quadratic models of these functions.
To be specific, we use quadratic models obtained by underdetermined interpolation based on the derivative-free symmetric Broyden update, detailed in \cref{subsec:symmetric-broyden-updates}.

At the~$k$th iteration, we denote by~$\objm[k]$ the quadratic model of~$\obj$, and by~$\conm[k]{i}$ the quadratic model of~$\con{i}$, for all~$i \in \iub \cup \ieq$.
These models are built on an interpolation set~$\xpt[k] \subseteq \R^n$, which is maintained by the method and updated along the iterations.
It changes at most one point of~$\xpt[k]$ at each iteration, and ensures that~$\iter[k] \in \xpt[k]$, where~$\iter[k] \in \R^n$ denotes the~$k$th iterate.
% Inspired by the performances of the solvers \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa} of Powell, we decide to base our models~$\objm[k]$ and~$\conm[k]{i}$, for~$i \in \iub \cup \ieq$, on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).

The initial models~$\objm[0]$ and~$\conm[0]{i}$, for~$i \in \iub \cup \ieq$, are built on the initial interpolation set~$\xpt[0] \subseteq \R^n$, defined as follows according to \citeauthor{Powell_2009}~\cite{Powell_2009}.
The user provides a number~$m$, satisfying
\begin{equation*}
    n + 2 \le m \le \frac{1}{2} (n + 1) (n + 2),
\end{equation*}
which will be the number interpolation points at each iteration.
We are also provided with an initial guess~$\iter[0] \in \R^n$ satisfying~$\xl \le \iter[0] \le \xu$ and an initial trust-region radius~$\rad[0] > 0$ that satisfies
\begin{equation*}
    \rad[0] \le \frac{1}{2} \min_{i \in \set{1, 2, \dots, n}} (\xu_i - \xl_i),
\end{equation*}
so that~$\xu_i \ge \xl_i + 2 \rad[0]$ for all~$i \in \set{1, 2, \dots, n}$.
Further, to avoid conflicts between the bounds and the interpolation points, the initial guess is modified so that each component is either on a bound or keeps a distance of at least~$\rad[0]$ from each bound.
The first~$n + 1$ points of~$\xpt[0] = \set{y^1, y^2, \dots, y^m}$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0]                      && \quad \text{if~$i = 1$,}\\
    & \iter[0] + \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\xl_{i - 1} \le \iter[0]_{i - 1} < \xu_{i - 1}$,}\\
    & \iter[0] - \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\iter[0]_{i - 1} = \xu_{i - 1}$,}
\end{empheq}
and the following~$\min \set{n, m - n - 1}$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0] - \rad[0] e_{i - n - 1}  && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\xl_{i - n - 1} < \iter[0]_{i - n - 1} \le \xu_{i - n - 1}$,}\\
    & \iter[0] + 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xl_{i - n - 1}$,}\\
    & \iter[0] - 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xu_{i - n - 1}$,}
\end{empheq}
where~$e_i$ denotes the~$i$th standard coordinate vector of~$\R^n$, i.e., the~$i$th column of~$I_n$.
If~$m > 2n + 1$, for~$i \in \set{2n + 2, 2n + 3, \dots, m}$, we set
\begin{equation*}
    y^i \eqdef y^{p(i) + 1} + y^{q(i) + 1} - \iter[0],
\end{equation*}
where~$p$ and~$q$ are defined by
\begin{equation*}
    p(i) \eqdef i - n - 1 - n \kappa(i) \quad \text{with} \quad \kappa(i) \eqdef \floor[\bigg]{\frac{i - n - 2}{n}},
\end{equation*}
\nomenclature[Of]{$\floor{\cdot}$}{Floor operator}%
and
\begin{empheq}[left={q(i) \eqdef \empheqlbrace}]{alignat*=2}
    & p(i) + \kappa(i)      && \quad \text{if~$p(i) + \kappa(i) \le n$,}\\
    & p(i) + \kappa(i) - n  && \quad \text{otherwise.}
\end{empheq}
We point out that if~$m \le 2n + 1$ and~$\xl < \iter[0] < \xu$, then the interpolation set~$\xpt[0]$ is essentially the interpolation set studied in \cref{sec:optimal-interpolation-set}, which focus on~$\rad[0] = 1$.
We have shown that this set is optimal for~$m = 2n + 1$, in a sense specified in \cref{sec:optimal-interpolation-set}.
Therefore, as Powell did, we take the value~$m = 2n + 1$ by default.

An advantage of choosing such an initial interpolation set is that the coefficients of the minimum-norm quadratic interpolation model can be directly evaluated.
See~\cite[\S~9]{Powell_2009} for the detailed calculations.

Once the initial models are constructed, they will be maintained by the derivative-free symmetric Broyden update, in the same way as \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.
See~\cite{Powell_2004b,Powell_2004c},~\cite[\S~4]{Powell_2006}, and~\cite[\S~4]{Powell_2009} for details.

\subsection{A derivative-free trust-region \glsfmtshort{sqp} framework}

We present in this section the derivative-free trust-region \gls{sqp} framework employed by \gls{cobyqa}.
We denote for convenience by~$\lagm[k]$\nomenclature[Fh]{$\lagm$}{Quadratic model of~$\lag$} the Lagrangian function evaluated on the models, i.e.,
\begin{equation*}
    \lagm[k](\iter, \lm) \eqdef \objm[k](\iter) + \sum_{\mathclap{i \in \iub \cup \ieq}} \lm_i \conm[k]{i}(\iter), \quad \text{for~$\iter \in \R^n$ and~$\lm_i \in \R$, with~$i \in \iub \cup \ieq$.}
\end{equation*}
As in \cref{sec:sqp-trust-region}, the merit function we consider is the~$\ell_2$-merit function, defined for a given penalty parameter~$\gamma^k \ge 0$ by
\begin{equation*}
    \merit[k](\iter) \eqdef \obj(x) + \gamma^k \sqrt{\sum_{i \in \iub} \posp{\con{i}(\iter)}^2 + \sum_{i \in \ieq} \abs{\con{i}(\iter)}^2}, \quad \text{for~$\iter \in \R^n$.}
\end{equation*}
We denote by~$\meritm[k]$ the~$\ell_2$-merit function computed on the \gls{sqp} subproblem, i.e.,
\begin{equation}
    \label{eq:l2-merit-function-model}
    \meritm[k](\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma^k \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation}
where~$\Phi$ is defined by
\begin{equation}
    \label{eq:l2-merit-function-model-penalty}
    \Phi(d) \eqdef \sqrt{\sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2}.
\end{equation}
The framework is given in \cref{alg:derivative-free-trust-region-sqp}, which hides many details, including the definition of \enquote{convergence} in the loop, the calculation of~$\step[k]$, the update of~$\lm[k]$, and the geometry improvement of the interpolation set, which will be specified in \cref{subsec:managing-trust-region-radius,subsec:solving-trust-region-subproblem,subsec:least-squares-lagrange-multipliers,subsec:geometry-improvement}, respectively.

\begin{algorithm}
    \caption{Derivative-free trust-region \glsfmtshort{sqp} method}
    \label{alg:derivative-free-trust-region-sqp}
    \DontPrintSemicolon
    \KwData{Initial guess~$\iter[0] \in \R^n$, estimated Lagrange multiplier~$\lm[0] = [\lm[0]_i]_{i \in \iub \cup \ieq}^{\T}$, initial trust-region radius~$\rad[0] > 0$, and parameters~$0 < \eta_1 \le \eta_2 < 1$ and~$0 < \theta_1 < 1 < \theta_2$.}
    Set the penalty parameter~$\gamma^{-1} \gets  0$\;
    Build the initial interpolation set~$\xpt[0] \subseteq \R^n$ described in \cref{subsec:interpolation-based-quadratic-models}\;
    \For{$k = 0, 1, \dots$ until convergence}{
        Update~$\objm[k]$ and~$\conm[k]{i}$ for~$i \in \iub \cup \ieq$ as mentioned in \cref{subsec:interpolation-based-quadratic-models}\;
        Set the trial step~$\step[k] \in \R^n$ to an approximate solution to
        \begin{subequations}
            \label{eq:derivative-free-trust-region-sqp-subproblem}
            \begin{algomathalign}
                \min        & \quad \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
                \text{s.t.} & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step \le 0, ~ i \in \iub,\\
                            & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                            & \quad \norm{\step} \le \rad[k],\\
                            & \quad \step \in \R^n, \nonumber
            \end{algomathalign}
        \end{subequations} \nllabel{alg:derivative-free-trust-region-sqp-subproblem}
        Pick a penalty parameter~$\gamma^k \ge \max \set{\gamma^{k - 1}, \norm{\lm[k]}}$ providing~$\meritm[k](\step[k]) < \meritm[k](0)$ \nllabel{alg:derivative-free-trust-region-sqp-penalty}\;
        Evaluate the trust-region ratio
        \begin{algomathdisplay}
            \ratio[k] \gets \frac{\merit[k](\iter[k]) - \merit[k](\iter[k] + \step[k])}{\meritm[k](0) - \meritm[k](\step[k])}
        \end{algomathdisplay}
        \eIf{$\ratio[k] > 0$}{
            Choose a point~$\bar{y} \in \xpt[k]$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-1}
        }{
            Choose a point~$\bar{y} \in \xpt[k] \setminus \set{\iter[k]}$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-2}
        }
        Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k] \setminus \set{\bar{y}}) \cup \set{\iter[k] + \step[k]}$\;
        Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$\; \nllabel{alg:derivative-free-trust-region-sqp-iterate}
        Estimate the Lagrange multiplier~$\lm[k + 1] = [\lm[k + 1]_i]_{i \in \iub \cup \ieq}$\; \nllabel{alg:derivative-free-trust-region-sqp-multipliers}
        Update the trust-region radius
        \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
            & \theta_1 \rad[k],  && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
            & \rad[k],           && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
            & \theta_2 \rad[k],  && \quad \text{otherwise}
        \end{algoempheq} \label{alg:derivative-free-trust-region-sqp-radius}
        Improve the geometry of~$\xpt[k + 1]$ if necessary\; \label{alg:derivative-free-trust-region-sqp-geometry}
    }
\end{algorithm}

In the implementation of \cref{alg:derivative-free-trust-region-sqp-iterate},~$\iter[k + 1]$ is always set to a best point in~$\xpt[k + 1]$ according to~$\merit[k]$, in the sense that
\begin{equation*}
    \iter[k + 1] \in \argmin_{y \in \xpt[k + 1]} \merit[k](y).
\end{equation*}
If~$\iter[k]$ is optimal in~$\xpt[k + 1]$ according to~$\merit[k]$, then we choose~$\iter[k + 1] = \iter[k]$, even if there are other optimal points.
Note however that we cannot naively set~$\iter[k + 1]$ to be either~$\iter[k] + \step[k]$ if~$\ratio[k] > 0$, or~$\iter[k]$ otherwise.
This is because~$\iter[k]$ is a best point in~$\xpt[k]$ according to~$\merit[k - 1]$, but it may not be the best one according to~$\merit[k]$.

% In a practical implementation, the quadratic models on \cref{alg:derivative-free-trust-region-sqp-models} of \cref{alg:derivative-free-trust-region-sqp} are not computed from scratch, because only one point differs~$\xpt[k + 1]$ from~$\xpt[k]$.
% Details on this update mechanism are given in \cref{subsec:implementation-symmetric-broyden-update}.

\subsection{Solving the trust-region \glsfmtshort{sqp} subproblem}
\label{subsec:solving-trust-region-subproblem}

To solve the trust-region \gls{sqp} subproblem~\cref{eq:derivative-free-trust-region-sqp-subproblem}, we employ a Byrd-Omojokun approach.
It first generates a normal step~$\nstep[k]$ as the least-norm solution to
\begin{subequations}
    \label{eq:cobyqa-normal}
    \begin{align}
        \min        & \quad \sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2\\
        \text{s.t.} & \quad \xl \le \iter[k] + \step \le \xu,\\
                    & \quad \norm{\step} \le \zeta \rad[k],\\
                    & \quad \step \in \R^n,
    \end{align}
\end{subequations}
for some~$\zeta \in (0, 1)$\nomenclature[Sc]{$(a, b)$}{Open set~$\set{\iter \in \R : a < \iter < b}$ with~$a < b$}.
Further, it generates a tangential step~$\tstep[k]$ by solving
\begin{subequations}
    \label{eq:cobyqa-tangential-original}
    \begin{align}
        \min        & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.} & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub,\\
                    & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                    & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                    & \quad \norm{\nstep[k] + \step} \le \rad[k],\\
                    & \quad \step \in \R^n,
    \end{align}
\end{subequations}
and sets the composite step~$\step[k] = \nstep[k] + \tstep[k]$.
Details on the calculations of the tangential and normal steps are provided in \cref{sec:cobyqa-tangential,sec:cobyqa-normal}, respectively.
In particular, the method we use to approximately minimize a quadratic subject to linear constraints and a trust-region constraint necessitates
\begin{enumerate}
    \item the origin to be feasible, and
    \item the trust region to be centered on the origin.
\end{enumerate}
The first requirement is satisfied by the tangential subproblem~\cref{eq:cobyqa-tangential-original}, but the second is not.
To cope with this difficulty, we can solve instead
\begin{subequations}
    \label{eq:cobyqa-tangential}
    \begin{align}
        \min        & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.} & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub, \label{eq:cobyqa-tangential-ub}\\
                    & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq, \label{eq:cobyqa-tangential-eq}\\
                    & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                    & \quad \norm{\step} \le \sqrt{(\rad[k])^2 - \norm{\nstep[k]}^2}, \label{eq:cobyqa-tangential-tr}\\
                    & \quad \step \in \R^n.
    \end{align}
\end{subequations}
In doing so, we would have
\begin{equation*}
    \norm{\step[k]} = \norm{\nstep[k] + \tstep[k]} \le \max_{d \in \R^n} \set[\Big]{\norm{d} + \sqrt{(\rad[k])^2 - \norm{\step}^2} : \norm{d} \le \rad[k]} = \sqrt{2} \rad[k].
\end{equation*}
Therefore, to maintain the property~$\norm{\step[k]} \le \rad[k]$, we replace the trust-region constraint of the tangential subproblem~\cref{eq:cobyqa-tangential-tr} with
\begin{equation}
    \label{eq:cobyqa-trust-region-radius}
    \norm{\step} \le \sqrt{\frac{(\rad[k])^2}{2} - \norm{\nstep[k]}^2}.
\end{equation}
Of course, we must ensure that~$\norm{\nstep[k]} \le \rad[k] / \sqrt{2}$, so that the right-hand side in~\cref{eq:cobyqa-trust-region-radius} is well-defined.
To do so, we select~$\zeta$ to satisfy~$\zeta \le 1 / \sqrt{2}$.
To always provide some elbow room for the tangential step, we restrict the previous condition to~$\zeta < 1 / \sqrt{2}$, and we finally choose for \gls{cobyqa}
\begin{equation*}
    \zeta = \frac{2 \sqrt{2}}{5}.
\end{equation*}

% Theoretically, it is possible to evaluate the composite step directly.
% However, the methods used to solve the subproblems usually require the trust-region center to be feasible, which is not the case for the composite subproblem.
% Therefore, we modify the tangential subproblem to make the origin the trust-region center, which is then feasible.
% Therefore, we build explicitely the tangential step.
% See Trust-Region Methods, p.~660.

\subsection{Least-squares Lagrange multipliers}
\label{subsec:least-squares-lagrange-multipliers}

We now provide details on the strategy employed by \gls{cobyqa} to estimate the Lagrange multipliers on \cref{alg:derivative-free-trust-region-sqp-multipliers} of \cref{alg:derivative-free-trust-region-sqp}.

Recall that the \gls{sqp} method can be regarded as an approximate Newton method on the \gls{kkt} system.
Therefore, given the iterate~$\iter[k + 1]$, it is natural to set the estimated Lagrange multipliers~$\lm[k + 1]$ to the one that attempt to satisfy the \gls{kkt} conditions as much as possible using the information available so far.
We then let~$\lm[k + 1]$ be the least-norm solution to
\begin{subequations}
    \begin{align}
        \min        & \quad \norm[\bigg]{\nabla \objm[k](\iter[k + 1]) + \sum_{i \in \iub \cup \ieq} \lm_i \nabla \conm[k]{i}(\iter[k + 1])}\\
        \text{s.t.} & \quad \lm_i \conm[k]{i}(\iter[k + 1]) = 0, ~ i \in \iub \label{eq:least-squares-lagrange-multipliers-complementary-slackness}\\
                    & \quad \lm_i \ge 0, ~ i \in \iub,\\
                    & \quad \lm = [\lm_i]_{i \in \iub \cup \ieq},
    \end{align}
\end{subequations}
which is then referred to as the \emph{least-squares Lagrange multiplier}~\cite{Dussault_1995}.
Note that this problem can be easily simplified as follows.
For all the indices~$i \in \iub$ such that~$\conm[k]{i}(\iter[k + 1]) \neq 0$, we necessarily have~$\lm[k + 1]_i = 0$.
Therefore, the linear constraints~\cref{eq:least-squares-lagrange-multipliers-complementary-slackness} can be removed from the problem by considering only the indices in
\begin{equation*}
    \ieq \cup \set{i \in \iub : \conm[k]{i}(\iter[k + 1]) = 0},
\end{equation*}
and by setting the remaining components of the least-squares Lagrange multiplier to zero.
% Another possibility, leading to a slightly different problem, is to consider only the indices in
% \begin{equation*}
%     \ieq \cup \set{i \in \iub : \conm[k]{i}(\iter[k + 1]) \le 0},
% \end{equation*}
% and to set the remaining components of the least-squares Lagrange multiplier to zero.
This is the method employed by \gls{cobyqa}.
Details on the calculations of the least-squares Lagrange multipliers are provided in \cref{sec:cobyqa-lagrange-multipliers}.

\subsection{Managing the trust-region radius}
\label{subsec:managing-trust-region-radius}

Inspired by the performance of \gls{uobyqa}, \gls{newuoa}, \gls{bobyqa}, and \gls{lincoa} (see \cref{subsec:uobyqa,subsec:newuoa-bobyqa-lincoa}), we employ the following paradigm for managing the trust-region radius in \gls{cobyqa}, proposed by Powell~\cite{Powell_2002,Powell_2006,Powell_2009}, in place of \cref{alg:derivative-free-trust-region-sqp-radius} or \cref{alg:derivative-free-trust-region-sqp}.
It consists in maintaining both the trust-region radius~$\rad[k] > 0$ and a lower-bound of it~$\radlb[k] > 0$.
The idea behind this technique is to use~$\rad[k]$ as the trust-region radius in the trust-region subproblem~\cref{eq:trust-region-sqp-subproblem}, and~$\radlb[k]$ to maintain an adequate distance between the points in~$\xpt[k]$.
Further, the method never increases~$\radlb[k]$, but adapt the value of~$\rad[k]$ in a typical trust-region way.
Of course, the method always ensures that~$\rad[k] \ge \radlb[k]$.
As noted by \citeauthor{Powell_2002}, allowing trial step to have a length larger than~$\radlb[k]$ prevent loss in efficiency that occurred otherwise in his software \gls{uobyqa}.

The update of the trust-region radius~$\rad[k]$ is given in \cref{alg:update-trust-region-radius}.
The parameters chosen in \gls{cobyqa} are~$\eta_1 = 0.1$,~$\eta_2 = 0.7$,~$\eta_3 = 1.4$,~$\theta_1 = 0.5$, and~$\theta_2 = \sqrt{2}$.
This update is entertained at each iteration.

\begin{algorithm}
    \caption{Updating the trust-region radius}
    \label{alg:update-trust-region-radius}
    \DontPrintSemicolon
    \KwData{Current lower bound on the trust-region radius~$\radlb[k] > 0$, current trust-region radius~$\rad[k] \ge \radlb[k]$, current trust-region ratio~$\ratio[k] \in \R$, current trial step~$\step \in \R^n$, and parameters~$0 < \eta_1 \le \eta_2 < 1 \le \eta_3$ and~$0 < \theta_1 < 1 < \theta_2$.}
    \KwResult{Updated trust-region radius~$\rad[k + 1]$.}
    Update the trust-region radius
    \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
        & \theta_1 \rad[k]                                                                      && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
        & \min \set{\theta_1 \rad[k], \norm{\step}}                                             && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
        & \min \set{\theta_2 \rad[k], \max \set{\theta_1 \rad[k], \theta_1^{-1} \norm{\step}}}  && \quad \text{otherwise}
    \end{algoempheq}
    \If{$\rad[k + 1] \le \eta_3 \radlb[k]$}{
        $\rad[k + 1] \gets \radlb[k]$\;
    }
\end{algorithm}

As we mentioned already, the method maintains~$\rad[k] \ge \radlb[k]$ and it never increases~$\radlb[k]$.
Therefore, the value of~$\radlb[k]$ is decreased only if~$\rad[k] = \radlb[k]$.
Moreover, since~$\radlb[k]$ is designed to maintain a good distance between the interpolation points, it must be decreased only if the performance of the models is poor.
Hence, it is decreased only if the trial step~$\norm{\step[k]}$ is small compared with~$\rad[k]$ and the trust-region ratio~$\ratio[k]$ is small.
Otherwise, it is maintained, i.e.,~$\radlb[k + 1] = \radlb[k]$.
\Cref{alg:reducing-lower-bound-trust-region-radius} presents the method employed by \gls{cobyqa} to reduce~$\radlb[k]$.
The parameters chosen in \gls{cobyqa} are~$\eta_4 = 16$,~$\eta_5 = 250$, and~$\theta_3 = 0.1$.

\begin{algorithm}
    \caption{Reducing the lower bound on the trust-region radius}
    \label{alg:reducing-lower-bound-trust-region-radius}
    \DontPrintSemicolon
    \KwData{Final trust-region radius~$\radlb[\infty] > 0$, current lower bound on the trust-region radius~$\radlb[k] \ge \radlb[\infty]$, updated trust-region radius~$\rad[k + 1] \ge \radlb[k]$, and parameters~$1 \le \eta_4 < \eta_5$ and~$0 < \theta_3 < 1$.}
    \KwResult{Reduced lower bound on trust-region radius~$\radlb[k + 1]$ and modified trust-region radius~$\rad[k + 1]$.}
    \If{$\radlb[k] = \radlb[\infty]$}{
        Terminate the optimization method\; \nllabel{alg:reducing-lower-bound-trust-region-radius-stop}
    }
    Update the lower bound on the trust-region radius
    \begin{algoempheq}[left={\radlb[k + 1] \gets \empheqlbrace}]{alignat*=2}
        & \theta_3 \radlb[k]                && \quad \text{if~$\eta_5 < \radlb[k] / \radlb[\infty]$,}\\
        & \sqrt{\radlb[k] \radlb[\infty]}   && \quad \text{if~$\eta_4 < \radlb[k] / \radlb[\infty] \le \eta_5$,}\\
        & \radlb[\infty]                    && \quad \text{otherwise}
    \end{algoempheq}
    Update the trust-region radius~$\rad[k + 1] \gets \max \set{\rad[k + 1], \radlb[k + 1]}$\;
\end{algorithm}

If \cref{alg:reducing-lower-bound-trust-region-radius-stop} of \cref{alg:reducing-lower-bound-trust-region-radius} is reached, we consider that the optimization method should stop, and that the method is successful.
This is because~$\radlb[k]$ measures to some extend the distance between the interpolation points.

\subsection{Updating the interpolation set}

We now detail the choice of~$\bar{y}$ in \cref{alg:derivative-free-trust-region-sqp-remove-1,alg:derivative-free-trust-region-sqp-remove-2} of \cref{alg:derivative-free-trust-region-sqp}.
Let us first consider the case~$\ratio[k] \ge 0$.
We want to replace a point from~$\xpt[k]$ by~$\iter[k] + \step[k]$ to obtain~$\xpt[k + 1]$.
We denote by~$\bar{\iter}$ the closest point from~$\iter[k]$ that solves
\begin{equation*}
    \min_{y \in \xpt[k]} \merit[k](y).
\end{equation*}
This point is not necessarily~$\iter[k]$, because the penalty parameter is already updated.
If several such points exists, we select any of them.
Further, \gls{dfo} methods usually set~$\bar{y}$ to be a solution to
\begin{equation*}
    \max_{y \in \xpt[k]} \norm{y - \bar{\iter}}.
\end{equation*}
This is because we want the model to be accurate only locally, around the best point.
Although this choice is possible, we decide in \gls{cobyqa} to set~$\bar{y}$ to be a solution to
\begin{equation}
    \label{eq:choice-point-to-remove-trust-region}
    \max_{y \in \xpt[k]} \abs{\omega(y)} \norm{y - \bar{\iter}}^4,
\end{equation}
where~$\omega(y)$ is a scaling factor, detailed below.
Recall from \cref{subsec:implementation-symmetric-broyden-update} that the inverse of the coefficient matrix of the interpolation problem is maintained.
The corresponding updating formula, detailed in~\cite[Eq.~(2.12)]{Powell_2004c} has a scalar denominator.
We then set~$\omega(y)$ to be this denominator if~$y \in \xpt[k]$ were to be replaced with~$\iter[k] + \step[k]$.
This is because we want both the points to be close from each others, and this denominator to be far away from zero to avoid numerical difficulties.
The choice of the formula~\cref{eq:choice-point-to-remove-trust-region} is taken from \gls{lincoa}, the most recent \gls{dfo} solver of \citeauthor{Powell_2015}.
He also made very similar choices for \gls{newuoa}~\cite[Eq.~(7.4)]{Powell_2006} and \gls{bobyqa}~\cite[Eq.~(6.1)]{Powell_2009}.

Coping with the case~$\ratio[k] < 0$ is now clear.
We set~$\bar{y}$ to be a solution to
\begin{equation*}
    \max_{y \in \xpt[k] \setminus \set{\iter[k]}} \abs{\omega(y)} \norm{y - \bar{\iter}}^4,
\end{equation*}
for the same reasons.

Note that a possibility that has stronger theoretical motivations would be to set~$\bar{y}$ to be the point that would make~$\xpt[k + 1]$ being~$\Lambda$-poised (see \cref{subsec:symmetric-broyden-updates}) in some set, say
\begin{equation}
    \label{eq:ball-lambda-poisedness}
    \set{x \in \R^n : \norm{x - \bar{\iter}} \le \radlb[k]},
\end{equation}
with the least possible~$\Lambda$.
This technique has however a major drawback: it is extremely expensive, and would require to minimize~$\card(\xpt[k + 1])$ absolute values of quadratic functions subject to~\cref{eq:ball-lambda-poisedness} at each iteration.
Hence, from a clear computational perspective, we decide not employ this technique in \gls{cobyqa}.

\subsection{Geometry of the interpolation set}
\label{subsec:geometry-improvement}

We now provide details for \cref{alg:derivative-free-trust-region-sqp-geometry} of \cref{alg:derivative-free-trust-region-sqp}.
As we mentioned in \cref{ch:interpolation}, the interpolation set~$\xpt[k]$ is adequate only if it is poised, i.e., only if the interpolation problem admits a solution for any function that is interpolated.
Moreover, we may wish that~$\xpt[k]$ is~$\Lambda$-poised in
\begin{equation*}
    \set{\iter \in \R^n : \norm{x - \iter[k]} \le \radlb[k]},
\end{equation*}
for some reasonably low~$\Lambda$, because the purpose of~$\radlb[k]$ is to maintain adequate distance between the interpolation points.
However, \cref{alg:derivative-free-trust-region-sqp} never ensures that such properties hold.
It is known that model-based methods tends in practice to lose the poisedness property of their interpolation set as the iterations progress.
To cope with this difficulty, model-based \gls{dfo} methods are usually modified to include geometry-improving mechanisms~\cite{Conn_Scheinberg_Vicente_2008a,Conn_Scheinberg_Vicente_2008b,Fasano_Morales_Nocedal_2009}.

We present in this section the geometry-improving mechanism that we employ in \gls{cobyqa}, which is adapted from \gls{bobyqa}~\cite{Powell_2009}.
% Some trust-region iterations are replaced with a geometry-improving iteration.
A point~$\bar{y} \in \xpt[k + 1]$ is chosen to be replaced by another one~$\iter[k + 1] + \rstep[k + 1]$, where the \emph{restoration step}~$\rstep[k + 1] \in \R^n$ is chosen to improve the geometry of~$\xpt[k + 1]$.

First of all, the point~$\bar{y}$ is chosen to be the closest point from~$\iter[k + 1]$ that solves
\begin{equation}
    \label{eq:choice-point-geometry-improving}
    \max_{y \in \xpt[k + 1]} \norm{y - \iter[k + 1]}.
\end{equation}
Further, similar to~\cite[Eq.~(6.6)]{Powell_2006}, we let~$\rstep[k + 1] \in \R^n$ be an approximate solution to
\begin{subequations}
    \label{eq:geometry-subproblem}
    \begin{align}
        \max        & \quad \abs{\lagp[\bar{y}](\iter[k + 1] + \step)}\\
        \text{s.t.} & \quad \xl \le \iter[k + 1] + \step \le \xu,\\
                    & \quad \norm{\step} \le \radlb[k + 1],\\
                    & \quad \step \in \R^n,
    \end{align}
\end{subequations}
where~$\lagp[\bar{y}]$ denotes the minimum Frobenius norm Lagrange polynomials for~$\xpt[k + 1]$ associated with~$\bar{y}$ (see \cref{def:lagrange-polynomials-minimum-norm}).
Details on the calculations of the restoration step are provided in \cref{sec:cobyqa-geometry-improving}.

The reason for choosing such an objective function is twofold.
First of all, recall that the updating formula detailed in~\cite[Eq.~(2.12)]{Powell_2004c} to compute the new inverse of the coefficient matrix of the interpolation problem has a scalar denominator.
Moreover,~\cite[Eq.~(6.5)]{Powell_2006} shows that this denominator is always lower bounded by~$\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])^2$.
Therefore, by selecting the restoration step~$\rstep[k + 1]$ to maximize~$\abs{\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])}$, we keep the denominator away from zero, and we avoid numerical difficulties.
Second of all, denote by~$B$ and~$\widetilde{B}$ the coefficient matrices of the interpolation problems on the original and the modified sets~$\xpt[k + 1]$, respectively.
\Citeauthor{Powell_2001}~\cite[\S~2]{Powell_2001} showed that
\begin{equation*}
    \lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1]) = \frac{\det \widetilde{B}}{\det B}.
\end{equation*}
This property also encourages us to let the restoration step~$\rstep[k + 1]$ solve~\cref{eq:geometry-subproblem}.

Now that the general framework of the geometry-improving phase is set up, we need to decide when to entertained such iterations.
First of all, recall that~$\radlb[k + 1]$ is designed to maintain adequate distance between the interpolation points.
Therefore, if~$\norm{y - \iter[k + 1]} \le \radlb[k + 1]$ for all~$y \in \xpt[k + 1]$, then no geometry-improving phase should be entertained.
In general, a geometry-improving step is entertained if the trust-region ratio is small,~$\ratio[k] < 0.1$ say.
This is because a low trust-region ratio usually indicates that the models do not represent the true function accurately.
The complete framework of a geometry-improving phase is given in \cref{alg:geometry-improving}.

\begin{algorithm}
    \caption{Geometry-improving phase}
    \label{alg:geometry-improving}
    \DontPrintSemicolon
    \KwData{Bounds~$\xl$ and~$\xu$, current interpolation set~$\xpt[k + 1] \subseteq \R^n$, current best point so far~$\iter[k + 1] \in \xpt[k + 1]$, current lower bound on the trust-region radius~$\radlb[k + 1] > 0$, and current penalty parameter~$\gamma^k$.}
    \KwResult{Updated interpolation set~$\xpt[k + 1]$, updated iterate~$\iter[k + 1]$, and updated Lagrange multiplier~$\lm[k + 1]$.}
    \If{$\norm{y - \iter[k + 1]} > \radlb[k + 1]$ for some~$y \in \xpt[k + 1]$}{
        Set~$\bar{y}$ to be the closest point from~$\iter[k + 1]$ that solves~\cref{eq:choice-point-geometry-improving}\;
        Set the step~$\rstep[k + 1] \in \R^n$ to be an approximate solution to~\cref{eq:geometry-subproblem}\;
        Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k + 1] \setminus \set{\bar{y}}) \cup \set{\iter[k + 1] + \rstep[k + 1]}$\;
        Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$ \label{alg:geometry-improving-iterate}\;
        Estimate the Lagrange multiplier~$\lm[k + 1] = [\lm[k + 1]_i]_{i \in \iub \cup \ieq}$ \label{alg:geometry-improving-multiplier}\;
    }
\end{algorithm}

We also entertain this geometry-improving phase without terminating the current trust-region iteration after reducing~$\rad[k + 1]$ if the step~$\step[k]$ generated at \cref{alg:derivative-free-trust-region-sqp-subproblem} of \cref{alg:derivative-free-trust-region-sqp} is small compared to the current trust-region radius,~$\norm{\step[k]} < \rad[k] / 2$ say.
Of course, the indices of the variables in \cref{alg:geometry-improving} need to be modified in such a case, as none of them are updated by the trust-region iteration.
However, if this process has been trigerred several times in a row, then the method decreases~$\radlb[k + 1]$ before generating a new trust-region step.
This mechanism has been developed by Powell in his solvers \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.

It is important to note that it is unlikely that~$\iter[k + 1]$ is modified in \cref{alg:geometry-improving-iterate}, because the step~$\rstep[k + 1]$ is not designed to provide any decrease of the merit function.
It is however not impossible, and if~$\iter[k + 1]$ is modified, it is important to update the multipliers in \cref{alg:geometry-improving-multiplier}.
This is the geometry-improving steps employed by \gls{cobyqa}.

\section{Management of bound and linear constraints}
\label{sec:simple-constraints}

The implementation of \gls{cobyqa} accepts three types of constraints, namely bound constraints, linear constraints, and nonlinear constraints.
From a theoretical standpoint, problems written in the form
\begin{align*}
    \min        & \quad \obj(\iter)\\
    \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub,\\
                & \quad \con{i}(\iter) = 0, ~ i \in \ieq,\\
                & \quad \iter \in \R^n,
\end{align*}
may have bound and linear constraints included in the constraints~$\set{\con{i}}_{i \in \iub \cup \ieq}$.
However, our implementation handles these types of constraints separately, for the following reasons.

% First of all, note that in the general form of nonlinearly-constrained problems~\cref{eq:problem-cobyqa}, we did not include the bound constraints~\cref{eq:problem-cobyqa-bd} in the inequality constraints~\cref{eq:problem-cobyqa-ub}.
First of all, bound constraints often represent inalienable physical or theoretical restrictions.
In many applications for which \gls{cobyqa} is designed, the objective function~\cref{eq:problem-cobyqa-obj} is not defined if the bounds~\cref{eq:problem-cobyqa-bd} are violated.
% For instance, the tuning of nonlinear optimization methods (see \cref{subsec:tuning-nonlinear-optimization-methods}) involves bounds that cannot be violated, as the optimization methods that are tuned may not be defined otherwise.
For an example, see the hyperparameter tuning problem given in \cref{subsec:machine-learning}.
For this reason, every point that \gls{cobyqa} encounters always respects these bounds, as is also the case for the \gls{bobyqa} method, presented in \cref{subsec:newuoa-bobyqa-lincoa}.
% When establishing the problem~\cref{eq:problem-cobyqa}, we assumed that~$\xl < \xu$.
% Note that this requirement is weak, as otherwise, the problem~\cref{eq:problem-cobyqa} would be either infeasible, or admit fix variables.
% Thus, note also that they are very simple constraints.
% It is, for example, trivial to check whether a point is feasible with respect to the bound constraints~\cref{eq:problem-cobyqa-bd}, and easy to project any point onto the bound constraints.
Therefore, \gls{cobyqa} handles bound constraints separately.
% This is another reason why \gls{cobyqa} handles them separately.

The linear constraints are usually much less restrictive.
In applications, the objective function is often well-defined even at points that are infeasible with respect to the linear constraints.
Therefore, we do not enforce \gls{cobyqa} to always respect the linear constraints.
However, when evaluating a model~$\conm[k]{i}$ of a linear constraint~$\con{i}$, we enforce~$\conm[k]{i} \equiv \con{i}$.
This reduces the computational complexity of evaluating all the models, and it also suppresses all damages that could be generated by computer rounding errors.

\section{Merit function and update of the penalty parameters}

We now discuss the merit function we use in \gls{cobyqa}.
Recall that we decided to use the~$\ell_2$-merit function.
This is because the~$\ell_2$-merit function~$\meritm[k]$ computed on the \gls{sqp} subproblem, given in~\cref{eq:l2-merit-function-model}, satisfy \cref{prop:byrd-omojokun-penalty}.
In what follows, we denote by~$\meritm_{\gamma}$ the~$\ell_2$ merit function evaluated on the \gls{sqp} subproblem, i.e.,
\begin{equation*}
    \meritm_{\gamma}(\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation*}
where~$\Phi$ is defined by~\cref{eq:l2-merit-function-model-penalty} and where~$\gamma$ is the corresponding penalty parameter.
Note that we did not include the bound constraints in the definition of the merit function, because the points visited by \gls{cobyqa} always satisfy the bound constraints~\cref{eq:problem-cobyqa-bd}.

\begin{proposition}
    \label{prop:byrd-omojokun-penalty}
    Given a composite step~$\step[k] = \nstep[k] + \tstep[k]$ generated by the Byrd-Omojokun approach, there exists~$\bar{\gamma} \ge 0$ such that for all~$\gamma \ge \bar{\gamma}$, we have~$\meritm_{\gamma}(\step[k]) \le \meritm_{\gamma}(0)$.
    Moreover, the least possible such value is
    \begin{empheq}[left={\bar{\gamma} = \empheqlbrace}]{alignat*=2}
        & 0                                                                                                                                                                         && \quad \text{if~$\Phi(\step[k]) = \Phi(0)$,}\\
        & \posp[\bigg]{\frac{\nabla \objm[k](\iter[k])^{\T} \step[k] + \frac{1}{2} (\step[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step[k]}{\Phi(0) - \Phi(\step[k])}}  && \quad \text{otherwise.}
    \end{empheq}
\end{proposition}

\begin{proof}
    Since~$\nstep[k]$ solves~\cref{eq:cobyqa-normal}, we have~$\Phi(\nstep[k]) \le \Phi(0)$.
    Moreover, since~$\tstep[k]$ satisfies~\cref{eq:cobyqa-tangential-ub,eq:cobyqa-tangential-eq}, we have~$\Phi(\nstep[k] + \tstep[k]) \le \Phi(\nstep[k])$ so that~$\Phi(\step[k]) \le \Phi(0)$.
    If~$\Phi(\step[k]) = \Phi(0)$, then~$\Phi(\nstep[k]) = \Phi(0)$ and hence,~$\nstep[k] = 0$ because~$\nstep[k]$ is the least-norm solution to~\cref{eq:cobyqa-normal}.
    In such a case, the result is clear, because the tangential step satisfies
    \begin{equation*}
        \nabla \objm[k](\iter[k])^{\T} \tstep[k] + \frac{1}{2} (\tstep[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \tstep[k]  \le 0.
    \end{equation*}
    Otherwise, if~$\Phi(\step[k]) < \Phi(0)$, the result is clear because~$\meritm_{\gamma}$ is linear with respect to~$\gamma$.
\end{proof}

The strategy of \gls{cobyqa} to increase the penalty parameter is given in \cref{alg:increase-penalty}.
Note that this strategy is well-defined, because of \cref{prop:byrd-omojokun-penalty}.
However, since we impose on \cref{alg:derivative-free-trust-region-sqp-penalty} of \cref{alg:derivative-free-trust-region-sqp} that~$\gamma^k \ge \gamma^{k - 1}$, the penalty parameter may become huge, which may lead to computational difficulties.
Therefore, we modify \cref{alg:derivative-free-trust-region-sqp} to include a mechanism proposed by \citeauthor{Powell_1994} in his solver \gls{cobyla}~\cite{Powell_1994}.
It consists in reducing~$\gamma^k$ whenever~$\radlb[k]$ is decreased.
The exact mechanism exmployed by \gls{cobyqa} is given in \cref{alg:reducting-penalty}.
For simplicity, we assume that~$\ieq = \emptyset$.
If~$\ieq \neq \emptyset$, \gls{cobyqa} will view each equality constraint as two inequality constraints when invoking \cref{alg:reducting-penalty}.

\begin{algorithm}
    \caption{Reducing the penalty parameter}
    \label{alg:reducting-penalty}
    \DontPrintSemicolon
    \KwData{Current interpolation set~$\xpt[k + 1] \subseteq \R^n$ and current penalty parameter~$\gamma^k \ge 0$.}
    \KwResult{Modified penalty parameter~$\gamma^k \ge 0$.}
    \KwNote{We assume that~$\ieq = \emptyset$ as otherwise, each equality constraint is viewed as two inequality constraints.}
    Set indices of the important constraints
    \begin{algomathdisplay}
        \iub^{\ast} \eqdef \set[\big]{i \in \iub : \min_{y \in \xpt[k + 1]} \con{i}(y) < \max_{y \in \xpt[k + 1]} 2 \con{i}(y)}
    \end{algomathdisplay}
    \eIf{$\mathcal{K} = \emptyset$}{
        Set~$\gamma^k \gets 0$\;
    }{
        Replace~$\gamma^k$ by
        \begin{algomathdisplay}
            \min \set[\bigg]{\frac{\max_{y \in \xpt[k + 1]} \obj(y) - \min_{y \in \xpt[k + 1]}  \obj(y)}{\min_{i \in \iub^{\ast}} \{ \max_{y \in \xpt[k + 1]} \con{i}(y) - \min_{y \in \xpt[k + 1]} \negp{\con{i}(y)} \}}, \gamma^k}
        \end{algomathdisplay} \label{alg:reducting-penalty-replace}
    }
\end{algorithm}
\nomenclature[Ob]{$\negp{\cdot}$}{Elementwise negative-part operator}%

The notation~$\negp{\cdot}$ in \cref{alg:reducting-penalty-replace} of \cref{alg:reducting-penalty} takes the negative part of a given number.
The term in \cref{alg:reducting-penalty-replace} is explained in~\cite[\S~4]{Powell_1994}.
Its numerator corresponds to a typical change in the objective function, while the denominator's term
\begin{equation*}
    \max_{y \in \xpt[k + 1]} \con{i}(y) - \min_{y \in \xpt[k + 1]} \negp{\con{i}(y)}
\end{equation*}
represents a typical change in the~$i$th constraint if~$\min_{y \in \xpt[k + 1]} \con{i}(y) \le 0$, and some distance to feasibility otherwise.
Of course, this term is very empirical, and other choices could be made.
This concludes the general description of \gls{cobyqa}.

\section{Summary of the method}

We present in this section a summary of the method employed by \gls{cobyqa}.

% \begin{figure}[ht]
%     \centering
%     \begin{tikzpicture}
%         \node[block] (init) {Set $\gamma^{-1} = 0$ and build $\mathcal{Y}^0$};
%         \node[block,below left of=init,node distance=3cm] (trstep) {Set~$d^k$ by solving (5.2.3)};
%         \node [decision,right of=trstep,node distance=6cm] (shortstep) {$\|d^k\| \ge \Delta^k / 2$};
%         \node [decision,right of=shortstep,node distance=4.5cm] (threerecent) {Three recent values of $d^k$ are small};

%         \path[line] (init) -- (trstep);
%         \path[line] (trstep) -- (shortstep);
%         \path[line] (shortstep) -- (threerecent);
%     \end{tikzpicture}
% \end{figure}
