%% contents/cobyqa-introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ a new \glsfmtlong{dfo} method}
\label{ch:cobyqa-introduction}

\section{Statement of the problem}

In this chapter, we introduce a new model-based \gls{dfo} method for solving nonlinearly-constrained problems of the form
\begin{subequations}
    \label{eq:problem-cobyqa}
    \begin{align}
        \min        & \quad \obj(\iter) \label{eq:problem-cobyqa-obj}\\
        \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub, \label{eq:problem-cobyqa-ub}\\
                    & \quad \con{i}(\iter) = 0, ~ i \in \ieq, \label{eq:problem-cobyqa-eq}\\
                    & \quad \xl \le x \le \xu, \label{eq:problem-cobyqa-bd}\\
                    & \quad \iter \in \R^n, \nonumber
    \end{align}
\end{subequations}
where~$\obj$ and~$\con{i}$ represent the objective and constraint functions, with~$i \in \iub \cup \ieq$ and the sets of indices~$\iub$ and~$\ieq$ being finite and disjoint, but possibly empty. 
The lower bounds~$\xl \in (\R \cup \set{-\infty})^n$ and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl < \xu$.
Note that the bound constraints~\cref{eq:problem-cobyqa-bd} are not included in the inequality constraints~\cref{eq:problem-cobyqa-ub}, because they must be dealt with separately, as detailed in \cref{sec:simple-constraints}.

We will develop a derivative-free trust-region \gls{sqp} method for solving the problem~\cref{eq:problem-cobyqa}.
The method, named~\gls{cobyqa} after \emph{\glsdesc{cobyqa}}, does not use derivatives of the objective function and the nonlinear constraint functions, but models them using underdetermined interpolation based on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).
This chapter presents the framework of the method, while the subproblems and the Python implementation will be discussed in \cref{ch:cobyqa-subproblems,ch:cobyqa-implementation}, respectively.

\section{The derivative-free trust-region \glsfmtshort{sqp} method}

We presented in \cref{ch:sqp} the basic trust-region \gls{sqp} method.
We now adapt this framework to derivative-free settings.

\subsection{Overview of the method}

\subsection{Interpolation-based quadratic models}

Recall that the basic trust-region \gls{sqp} method presented in \cref{alg:trust-region-sqp} uses the gradients and the Hessian matrices of the objective function~$\obj$ and the constraint functions~$\con{i}$, with~$i \in \iub \cup \ieq$.
Since we do not have access to such information, we use quadratic models of them, for which all derivative information are known.
As detailed in \cref{ch:interpolation}, to increase the performance of the method, we use quadratic models obtained by underdetermined interpolation.
Inspired by the performances of the solvers \gls{newuoa}, \gls{bobyqa}, and \gls{lincoa} of Powell, we decide to base our models on derivative-free symmetric Broyden updates (see \cref{subsec:symmetric-broyden-updates}).

At the~$k$th iteration, we note by~$\objm[k]$ the quadratic model of~$\obj$, and by~$\conm[k]{i}$ the quadratic model of~$\con{i}$, for all~$i \in \iub \cup \ieq$.
These models are built on an interpolation set~$\xpt[k] \subseteq \R^n$, which is maintained automatically by the method.
It changes at most one point of~$\xpt[k]$ at each iteration, and ensures that~$\iter[k] \in \xpt[k]$, where~$\iter[k] \in \R^n$ denotes the~$k$th iterate. 

\subsection{Least-squares Lagrange multipliers}

\subsection{Geometry of the interpolation set}

\section{Management of bound and linear constraints}
\label{sec:simple-constraints}

The implementation of \gls{cobyqa} accepts three types of constraints, namely bound constraints, linear constraints, and nonlinear constraints.
From a theoretical standpoint, problems written in the form
\begin{align*}
    \min        & \quad \obj(\iter)\\
    \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub,\\
                & \quad \con{i}(\iter) = 0, ~ i \in \ieq,\\
                & \quad \iter \in \R^n,
\end{align*}
may have bound and linear constraints included in some or all of the constraints~$\con{i}$, with~$i \in \iub \cup \ieq$.
However, it is crucial that the implementation of a solver handles these types of constraints separately, for the following reasons.

First of all, note that in the general form of nonlinearly-constrained problems~\cref{eq:problem-cobyqa}, we did not include the bound constraints~\cref{eq:problem-cobyqa-bd} in the inequality constraints~\cref{eq:problem-cobyqa-ub}.
This is because they often represent inalienable physical or theoretical restrictions.
In other words, in many applications, the objective function~\cref{eq:problem-cobyqa-obj} is not defined if the bounds constraints~\cref{eq:problem-cobyqa-bd} are violated.
For instance, the tuning of nonlinear optimization methods (see \cref{subsec:tuning-nonlinear-optimization-methods})  involves bounds that cannot be violated, as the optimizationmethods that are tuned may not be defined otherwise.
Very similar observations can be made on hyperparameter tuning in machine learning (see \cref{subsec:machine-learning}).
For this reason, every point that \gls{cobyqa} encounters always respects these bounds, as is also the case for the \gls{bobyqa} method, presented in \cref{subsec:newuoa-bobyqa-lincoa}.
When establishing the problem~\cref{eq:problem-cobyqa}, we assumed that~$\xl < \xu$.
Note that this requirement is weak, as otherwise, the problem~\cref{eq:problem-cobyqa} would be either infeasible, or admit fix variables.
Thus, note also that they are very simple constraints.
It is, for example, trivial to check whether a point is feasible with respect to the bound constraints~\cref{eq:problem-cobyqa-bd}, and easy to project any point onto the bound constraints.
This is another reason why \gls{cobyqa} handles them separately.

The linear constraints are usually much less restrictive.
The objective function is often well-defined even at points that are infeasible with respect to the linear constraints.
Therefore, we do not enforce \gls{cobyqa} to always respect the linear constraints.
However, when evaluating a model~$\conm[k]{i}$ of a linear constraint~$\con{i}$, we enforce~$\conm[k]{i} \equiv \con{i}$.
This reduces the computational complexity of evaluating all the models, and it also suppresses all damages that could be generated by computer rounding errors.

\section{Merit function and update of the penalty parameters}

\section{Summary of the method}

\begin{itemize}
    \item Theoretically, it is possible to evaluate the composite step directly.
    However, the methods used to solve the subproblems usually require the trust-region center to be feasible, which is not the case for the composite subproblem.
    Therefore, we modify the tangential subproblem to make the origin the trust-region center, which is then feasible.
    Therefore, we build explicitely the tangential step.
    See Trust-Region Methods, p.~660.
\end{itemize}
