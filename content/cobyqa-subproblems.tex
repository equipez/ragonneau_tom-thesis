%% contents/cobyqa-subproblems.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ solving the subproblems}
\label{ch:cobyqa-subproblems}

In this chapter, we present the methods employed by \gls{cobyqa} to solve its various subproblems, including the tangential subproblem~\cref{eq:cobyqa-tangential} (with a modified trust-region radius), the normal subproblem~\cref{eq:cobyqa-normal}, the least-squares problem~\cref{eq:least-squares-lagrange-multipliers-cobyqa} for estimating the Lagrange multiplier, and the geometry-improving subproblem~\cref{eq:geometry-subproblem}.

\section{The \glsfmtlong{tcg} method}

Trust-region methods often involve the minimization of a quadratic function subject to a trust-region constraint, i.e., a problem of the form
\begin{subequations}
    \label{eq:problem-tcg}
    \begin{align}
        \min        & \quad Q(\step)\\
        \text{s.t.} & \quad \norm{\step} \le \rad,\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
with~$Q \in \qpoly$ and~$\rad > 0$.
The usual convergence results for trust-region methods do not require a given solution~$\step[\ast]$ to~\cref{eq:problem-tcg} to be exact.
Rather, they only necessitate to satisfy the Cauchy decrease condition
\begin{equation*}
    Q(0) - Q(\step[\ast]) \ge c \norm{\nabla Q(0)} \min \set[\bigg]{\frac{\norm{\nabla Q(0)}}{\norm{\nabla^2 Q}}, \rad},
\end{equation*}
for some~$c \in (0, 1]$, where we assume that~$\norm{\nabla Q(0)} / \norm{\nabla^2 Q} = \infty$ if~$\nabla^2 Q \equiv 0$.

Therefore, in trust-region method, we solve~\cref{eq:problem-tcg} approximately.
A well-known method for evaluating~$\step[\ast]$ is the Steihaug-Toint \gls{tcg} method~\cite{Steihaug_1983,Toint_1981}, presented in this section\todo{Other methods exist}.
The framework for solving~\cref{eq:problem-tcg} using the \gls{tcg} method is given in \cref{alg:tcg}.
The idea of the algorithm is to entertain conjugate gradients iterations, and stop the computations if a step reaches the boundary of the trust region.

\begin{algorithm}
    \caption{Steihaug-Toint \glsfmtshort{tcg} method}
    \label{alg:tcg}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Trust-region radius~$\rad > 0$.}
    \KwResult{A step that approximately solve~\cref{eq:problem-tcg}.}
    Set the initial values~$\sstep[0] \gets 0$ and~$\pstep[0] \gets -\nabla Q(\sstep[0])$\;
    \For{$k = 0, 1, \dots$ until~$\norm{\pstep[k]} = 0$}{
        Set
        \begin{algoempheq}[left={\alpha_Q^k \gets \empheqlbrace}]{alignat*=2}
            & \frac{- \nabla Q(\sstep[k])^{\T} \pstep[k]}{(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k]}  && \quad \text{if~$(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k] > 0$,}\\
            & \infty                                                                                && \quad \text{otherwise}
        \end{algoempheq}
        Compute~$\alpha_{\rad}^k \gets \argmax \set{\alpha \ge 0 : \norm{\sstep[k] + \alpha \pstep[k]} \le \rad}$\nomenclature[Op]{$\argmax$}{Global maximizer operator}\;
        Set the steplength~$\alpha^k \gets \min \set{\alpha_Q^k, \alpha_{\rad}^k}$\;
        Update the step~$\sstep[k + 1] \gets \sstep[k] + \alpha^k \pstep[k]$\;
        \eIf{$\alpha^k = \alpha_{\rad}^k$}{
            Break\;
        }{
            Evaluate the ratio~$\beta^k \gets \norm{\nabla Q(\sstep[k + 1])}^2 / \norm{\nabla Q(\sstep[k])}^2$\;
            Update the step~$\pstep[k + 1] \gets -\nabla Q(\sstep[k]) + \beta^k \pstep[k]$\;
        }
    }
    The last value of~$\sstep[k]$ is the desired step\;
\end{algorithm}

This algorithm enjoys many good properties.
In particular, \citeauthor{Yuan_2000}~\cite{Yuan_2000} showed that the step~$\step[\ast]$ provided by the \gls{tcg} method provides a least half the reduction provided by an exact solution to~\cref{eq:problem-tcg}.
The \gls{tcg} method underlies the subproblem solvers employed by \gls{cobyqa}, as presented hereinafter.

\section{Solving the tangential subproblem}
\label{sec:cobyqa-tangential}

We now present the constrained variations of the \gls{tcg} method we use in \gls{cobyqa} to solve the tangential subproblem~\cref{eq:cobyqa-tangential}.
Recall that \gls{cobyqa} uses a modified trust-region radius, but this does not affect our discussion below.

\subsection{Bound-constrained case}

We present here the bound-constrained variation of the \gls{tcg} method designed by \citeauthor{Powell_2009} for his solver \gls{bobyqa}~\cite{Powell_2009}.
This is the method employed by \gls{cobyqa} when only bound constraints are provided (i.e., when~$\iub \cup \ieq = \empty$ in~\cref{eq:problem-cobyqa}).
In such a case, the trust-region \gls{sqp} subproblem is of the form
\begin{subequations}
    \label{eq:problem-tcg-bounds}
    \begin{align}
        \min        & \quad Q(\step) \label{eq:problem-tcg-bounds-obj}\\
        \text{s.t.} & \quad \xl \le \step \le \xu,\\
                    & \quad \norm{\step} \le \rad,\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
where the objective function~$Q$ is quadratic, the lower bounds~$\xl \in (\R \cup \set{-\infty})^n$, and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl \le 0$,~$\xu \ge 0$, and~$\xl < \xu$.
Note that these bounds are not the same as in~\cref{eq:problem-cobyqa}.

The method designed by \citeauthor{Powell_2009} is an active-set variation of the \gls{tcg} method.
At each iteration, a truncate conjugate gradient step is performed on the coordinates that are not fixed by a given working set.
If a new bound is hit during such iteration, the bound is added to the working set, and the procedure is restarted.
The working set is only enlarged through the iterations, which then ensures the termination of the method.

The initial working set is a subset of the active bounds at the origin.
Clearly, an active bound should not be included in the working set if a positive step along~$-\nabla Q(0)$ would depart from the bound, as the bound is never removed from the working set.
Therefore, the initial working set is set to be
\begin{equation}
    \label{eq:bounds-initial-working-set}
    \mathcal{W}^0 \eqdef \set[\bigg]{i \in \set{1, 2, \dots, n} : \xl_i = 0 ~ \text{and} ~ \frac{\partial Q}{\partial \iter_i}(0) \ge 0, ~ \text{or} ~ \xu_i = 0 ~ \text{and} ~ \frac{\partial Q}{\partial \iter_i}(0) \le 0}.
\end{equation}
The complete framework is described in \cref{alg:tcg-bounds}, where~$\Pi^k(v)$ is denotes the vector whose~$i$th component is~$v_i$ if~$i \notin \mathcal{W}^k$, and zero otherwise.

\begin{algorithm}
    \caption{Bound-constrained \glsfmtshort{tcg} method}
    \label{alg:tcg-bounds}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Bounds~$\xl$ and~$\xu$, and trust-region radius~$\rad > 0$.}
    \KwResult{A step that approximately solve~\cref{eq:problem-tcg-bounds}.}
    Set the initial values~$\sstep[0] \gets 0$,~$\mathcal{W}^0$ according to~\cref{eq:bounds-initial-working-set}, and~$\pstep[0] -\gets \Pi^0(\nabla Q(\sstep[0]))$\;
    \For{$k = 0, 1, \dots$ until~$\norm{\pstep[k]} = 0$}{
        Set
        \begin{algoempheq}[left={\alpha_Q^k \gets \empheqlbrace}]{alignat*=2}
            & \frac{- \nabla Q(\sstep[k])^{\T} \pstep[k]}{(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k]}  && \quad \text{if~$(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k] > 0$,}\\
            & \infty                                                                                && \quad \text{otherwise}
        \end{algoempheq}
        Compute~$\alpha_{\rad}^k \gets \argmax \set{\alpha \ge 0 : \norm{\sstep[k] + \alpha \pstep[k]} \le \rad}$\;
        Compute~$\alpha_B^k \gets \argmax \set{\alpha \ge 0 : \xl \le \sstep[k] + \alpha \pstep[k] \le \xu}$\;
        Set the steplength~$\alpha^k \gets \min \set{\alpha_Q^k, \alpha_{\rad}^k, \alpha_B^k}$\;
        Update the step~$\sstep[k + 1] \gets \sstep[k] + \alpha^k \pstep[k]$\;
        \uIf{$\alpha^k = \alpha_B^k$}{
            Add a new active constraint to~$\mathcal{W}^k$ to obtain~$\mathcal{W}^{k + 1}$\;
            Set~$\pstep[k + 1] \gets -\Pi^{k + 1}(\nabla Q(\sstep[k + 1]))$\;
        }
        \uElseIf{$\alpha^k = \alpha_{\rad}^k$}{
            Break\;
        }
        \Else{
            Preserve the working set~$\mathcal{W}^{k + 1} \gets \mathcal{W}^k$\;
            Evaluate the ratio~$\beta^k \gets \norm{\Pi^{k + 1}(\nabla Q(\sstep[k + 1]))}^2 / \norm{\Pi^{k + 1}(\nabla Q(\sstep[k]))}^2$\;
            Update the step~$\pstep[k + 1] \gets -\Pi^{k + 1}(\nabla Q(\sstep[k])) + \beta^k \pstep[k]$\;
        }
    }
    The last value of~$\sstep[k]$ is the desired step\;
\end{algorithm}

\Gls{cobyqa} employed a modification of this algorithm for solving its trust-region subproblem when the user supplied a bound-constrained problem.
The modification, also proposed by \citeauthor{Powell_2009} and implemented in \gls{bobyqa}~\cite{Powell_2009} is based on the following observation.
If the step~$\step[\ast]$ returned by \cref{alg:tcg-bounds} satisfies~$\norm{\step[\ast]} = \rad$, it is likely that the objective function in~\cref{eq:problem-tcg-bounds-obj} can be further decreased by moving this point round the trust-region boundary.
In fact, the global solution of~\cref{eq:problem-tcg-bounds} is on the trust-region boundary in such a case.
The method employed by \gls{cobyqa} then attempts to further reduce the objective function by returning an approximate solution to
\begin{align*}
    \min        & \quad Q(\step)\\
    \text{s.t.} & \quad \xl \le \step \le \xu,\\
                & \quad \norm{\step} \le \rad,\\
                & \quad \step \in \vspan \set{\Pi^{\ast}(\step[\ast]), \Pi^{\ast}(\nabla Q(\step[\ast]))} \subseteq \R^n,
\end{align*}
where~$\Pi^{\ast}$ denotes the function~$\Pi^{k}$ at the last iteration.
Note that a substantial reduction in~$Q$ is possible only if both~$\Pi^{\ast}(\nabla Q(\step[\ast]))$ and the angle between~$\Pi^{\ast}(\step[\ast])$ and~$-\Pi^{\ast}(\nabla Q(\step[\ast]))$ are important.
The method designed by \citeauthor{Powell_2009} attempts to move round the trust-region boundary only if
\begin{equation*}
    \norm{\Pi^{\ast}(\step[\ast])}^2 \norm{\Pi^{\ast}(\nabla Q(\step[\ast]))}^2 - [\Pi^{\ast}(\step[\ast])^{\T} \Pi^{\ast}(\nabla Q(\step[\ast]))]^2 \le \xi [Q(0) - Q(\step[\ast])]^2,
\end{equation*}
for some~$\xi \in (0, 1)$.
In \gls{cobyqa}, we have~$\xi = 10^{-4}$.
When the amelioration mechanism is entertain, it builds an orthogonal basis~$\set{\Pi^{\ast}(\step[\ast]), w}$ of~$\vspan \set{\Pi^{\ast}(\step[\ast]), \Pi^{\ast}(\nabla Q(\step[\ast]))}$ by computing the vector~$w \in \R^n$ that satisfy
\begin{empheq}[left=\empheqlbrace]{alignat*=1}
    & w^{\T} \Pi^{\ast}(\step[\ast]) = 0\\
    & w^{\T} \Pi^{\ast}(\nabla Q(\step[\ast])) < 0\\
    & \norm{w} = \norm{\Pi^{\ast}(\step[\ast])}.
\end{empheq}
Further, the method considers the function
\begin{equation*}
    \step(\theta) \eqdef \step[\ast] + (\cos \theta - 1) \Pi^{\ast}(\step[\ast]) + \sin \theta w, \quad \text{for~$0 \le \theta \le \pi / 4$,}
\end{equation*}
and solve
\begin{align*}
    \min        & \quad Q(\step(\theta))\\
    \text{s.t.} & \quad \xl \le \step(\theta) \le \xu,\\
                & \quad 0 \le \theta \le \pi / 4,
\end{align*}
the trust-region condition being automatically ensured by the choice of~$w$.

To solve approximately such a problem, the solver seeks for the greatest reduction in the objective function for a range of equally spaced values of~$\theta$, chosen to ensure the feasibility of the iterates.
If the value of the approximate solution is restricted by a bound, it is added to the working set~$\mathcal{W}^{\ast}$, and the refinement procedure is restarted.
Since the working set is only increased, this procedure terminates in at most~$n - \card(\mathcal{W}^{\ast})$ iterations, where~$\mathcal{W}^{\ast}$ denotes the number of active bounds at the end of the constrained \gls{tcg} procedure.

The bound-constrained \gls{tcg} procedure together with the improving mechanism is implemented in \gls{cobyqa} under the function \texttt{cobyqa.linalg.bvtcg}.

\subsection{Linearly-constrained case}

We now present the linearly-constrained variation of the \gls{tcg} method designed by \citeauthor{Powell_2015} for his solver \gls{lincoa}~\cite{Powell_2015}.
The original method is designed for linear inequality constraints, but is adapted here to include equality constraints.
This method is employed by \gls{cobyqa} when general constraints are provided (i.e., when~$\iub \cup \ieq \neq \emptyset$ in~\cref{eq:problem-cobyqa}).
In such a case, the trust-region \gls{sqp} subproblem is of the form
\begin{subequations}
    \label{eq:problem-tcg-general}
    \begin{align}
        \min        & \quad Q(\step)\\
        \text{s.t.} & \quad A \step \le b, \label{eq:problem-tcg-general-ub}\\
                    & \quad C \step = 0,\\
                    & \quad \norm{\step} \le \rad,\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
where the objective function~$Q$ is quadratic,~$A \in \R^{m_1 \times n}$,~$C \in \R^{m_2 \times n}$, and~$b \in \R^{m_1}$ satisfies~$b \ge 0$.
In this form, we included the bound constraints in the inequality constraints~\cref{eq:problem-tcg-general-ub} because the method we discuss below is a feasible method.
Therefore, the constraints will be respected.

The method designed by Powell is an active-set variation of the \gls{tcg} algorithm, which maintains the QR factorization of the matrix whose columns are the gradients of the active constraints.
As for \cref{alg:tcg-bounds}, if a new constraint is added to the working set, the procedure is restarted.
However, we allow constraints to be removed from the working set in this method.

\subsubsection{The working set}

In this method, the working set is not directly the active set at the current iterate, for the following reason.
Assume that an inequality constraint is positive and tiny at the origin~$\sstep[0] = 0$,~$b_j > 0$ say.
If~$j$ does not belong to the working set and if~$e_j^{\T} A \nabla Q(\sstep[0]) < 0$, then it is likely that the first generated step~$\sstep[1]$ has small norm small, as a step along the search direction~$\pstep[0] = -\nabla Q(\sstep[0])$ quickly exits the feasible set.
Therefore, we must consider a constraint as active whenever its residual becomes small.
More precisely, for some feasible~$\step \in \R^n$, we let
\begin{equation*}
    \mathcal{J}(\step) \eqdef \set{j \le m_1 : b_j - e_j^{\T} A \step \le \sigma \rad \norm{e_j^{\T} A}},
\end{equation*}
for some~$\sigma \in (0, 1)$, set to~$\sigma = 0.2$ in \gls{cobyqa}, and the initial working set is a subset of~$\mathcal{J}(\sstep[0])$.
Moreover, the initial search direction~$\pstep[0]$ should be close to~$-\nabla Q(\step[0])$ and prevent the point~$\sstep[1]$ to be close from~$\sstep[0]$.
To set such an initial search direction, we denote by~$\Pi^k(v)$ the unique solution to
\begin{subequations}
    \label{eq:tcg-linear-working-set}
    \begin{align}
        \min        & \quad \norm{\step - v}\\
        \text{s.t.} & \quad e_j^{\T} A \step, ~ j \in \mathcal{J}(\sstep[k]) \le 0,\\
                    & \quad C \step = 0,\\
                    & \quad \step \in \R^n. \nonumber
    \end{align}
\end{subequations}
Further, we set the search direction~$\pstep[0]$ to~$\Pi^0(-\nabla Q(\sstep[0]))$.
If~$e_j^{\T} A \sstep[0] < 0$ for some~$j$, then the point~$\sstep[1]$ will be further from this constraint than the initial guess.
Therefore, the working set~$\mathcal{W}^0$ is chosen to be~$\set{j \in \mathcal{J}(\sstep[0]) : e_j^{\T} A \sstep[0] = 0}$ (or a subset of it, so that~$\set{e_j^{\T} A : j \in \mathcal{W}^0}$ is a basis of~$\vspan \set{e_j^{\T} A : j \in \mathcal{J}(\sstep[0]), ~ e_j^{\T} A \sstep[0] = 0}$).

The solution of~\cref{eq:tcg-linear-working-set} is calculated using the \citeauthor{Goldfarb_Idnani_1983} method for quadratic programming~\cite{Goldfarb_Idnani_1983}.
It is an active-set method designed for minimizing positive definite quadratic function subject to linear constraints.
Using QR factorizations, it builds a linearly independent subset of the active constraints at the solution.
Therefore, after executing such the \citeauthor{Goldfarb_Idnani_1983} method, we have a solution to~\cref{eq:tcg-linear-working-set} together with a basis of the active set.
In fact, denote~$\hat{Q}R$ the QR factorization of the matrix whose columns are the gradients of the active constraints at the solution, and let~$\check{Q}$ be a matrix such that~$[\hat{Q}, \check{Q}]$ is orthogonal.
It turns out that the solution to~\cref{eq:tcg-linear-working-set} is~$\check{Q} \check{Q}^{\T} v$ (see~\cite[Eq.~(3.7)]{Powell_2015}).
Therefore, we have in particular~$\Pi^k(-v) = -\Pi^k(v)$.

\subsubsection{The \glsfmtshort{tcg} method}

We are now equiped to present the linearly-constrained \gls{tcg} method designed by \citeauthor{Powell_2015}.
The complete framework is described in \cref{alg:tcg-linear}.

\begin{algorithm}
    \caption{Linearly-constrained \glsfmtshort{tcg} method}
    \label{alg:tcg-linear}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Matrices~$A$ and~$C$, right-hand side~$b$, trust-region radius~$\rad > 0$, and constant~$\sigma \in (0, 1)$.}
    \KwResult{A step that approximately solve~\cref{eq:problem-tcg-general}.}
    Set the initial values~$\sstep[0] \gets 0$,~$\hat{k} = 0$,~$\pstep[0] \gets -\Pi^{\hat{k}}(\nabla Q(\sstep[0]))$\;
    \For{$k = 0, 1, \dots$ until~$\norm{\pstep[k]} = 0$}{
        Set
        \begin{algoempheq}[left={\alpha_Q^k \gets \empheqlbrace}]{alignat*=2}
            & \frac{- \nabla Q(\sstep[k])^{\T} \pstep[k]}{(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k]}  && \quad \text{if~$(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k] > 0$,}\\
            & \infty                                                                                && \quad \text{otherwise}
        \end{algoempheq}
        Compute~$\alpha_{\rad}^k \gets \argmax \set{\alpha \ge 0 : \norm{\sstep[k] + \alpha \pstep[k]} \le \rad}$\;
        Compute~$\alpha_L^k \gets \argmax \set{\alpha \ge 0 : A(\sstep[k] + \alpha \pstep[k]) \le b}$\;
        Set the steplength~$\alpha^k \gets \min \set{\alpha_Q^k, \alpha_{\rad}^k, \alpha_L^k}$\;
        Update the step~$\sstep[k + 1] \gets \sstep[k] + \alpha^k \pstep[k]$\;
        \uIf{$\alpha^k = \alpha_L^k$ and~$\norm{\sstep[k + 1]} \le (1 - \sigma) \rad$}{
            Update~$\hat{k} = k + 1$\;
            Set~$\pstep[k + 1] \gets -\Pi^{\hat{k}}(\nabla Q(\sstep[k + 1]))$\;
        }
        \uElseIf{$\alpha^k = \alpha_{\rad}^k$ or $\alpha^k = \alpha_L^k$ and~$\norm{\sstep[k + 1]} > (1 - \sigma) \rad$}{
            Break\;
        }
        \Else{
            Evaluate the ratio
            \begin{algomathdisplay}
                \beta^k \gets \frac{\Pi^{\hat{k}}(\nabla Q(\sstep[k + 1]))^{\T} (\nabla^2 Q) \pstep[k]}{(\pstep[k])^{\T} (\nabla^2 Q) \pstep[k]}
            \end{algomathdisplay}
            Update the step~$\pstep[k + 1] \gets -\Pi^{\hat{k}}(\nabla Q(\sstep[k])) + \beta^k \pstep[k]$\;
        }
    }
    The last value of~$\sstep[k]$ is the desired step\;
\end{algorithm}

It is important to note that the method stops if a new constraint at a point close from the trust-region boundary.
Although such a stopping criterion did not exist in \cref{alg:tcg-bounds}, it is implemented in the linearly-constrained case because constraints may be removed from the active set.

\subsubsection{Additional stopping criteria}

\Citeauthor{Powell_2015} also proposed two additional stopping criteria, to avoid doing unworthy computations.
First of all, the computations are stopped if~$\nabla Q(\sstep[k])$ is small along the current search direction, namely if
\begin{equation*}
    \alpha_{\rad}^k \abs{(\sstep[k])^{\T} \nabla Q(\sstep[k])} \le \nu [Q(0) - Q(\sstep[k])],
\end{equation*}
for some constant~$\nu > 0$, set to~$\nu = 0.01$ in \gls{cobyqa}.
Moreover, the computations are also stopped if the reduction provided by the current search direction is tiny compared to the reduction so far, that is if
\begin{equation*}
    Q(\sstep[k]) - Q(\sstep[k + 1]) \le \nu [Q(0) - Q(\sstep[k + 1])].
\end{equation*}

The linearly-constrained \gls{tcg} procedure with these additional stopping criteria is implemented in \gls{cobyqa} under the function \texttt{cobyqa.linalg.lctcg}.

\section{Solving the normal subproblem}
\label{sec:cobyqa-normal}

\section{Evaluating the least-squares Lagrange multiplier}
\label{sec:cobyqa-lagrange-multipliers}

\begin{itemize}
    \item How is it related to the original \gls{nnls} by considering the positive and negative parts?
\end{itemize}

\section{Solving the geometry-improving subproblem}
\label{sec:cobyqa-geometry-improving}
