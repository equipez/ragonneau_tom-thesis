%% contents/introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{Introduction}

\nomenclature[Fa]{$\obj$}{Real-valued objective function defined on~$\R^n$}%
\nomenclature[Fb]{$\con{i}$}{Real-valued constraint function defined on~$\R^n$, with~$i \in \iub \cup \ieq$}%
\nomenclature[Fc]{$\lag$}{Lagrangian function}%
\nomenclature[Na]{$\in$}{Set membership notation}%
\nomenclature[Nb]{$\subseteq$}{Set inclusion notation}%
\nomenclature[Nc]{$\qedsymbol$}{Halmos symbol}%
\nomenclature[Nd]{$A^{\T}$,~$v^{\T}$}{Transpose of a matrix or a vector}%
\nomenclature[Ne]{$I_n$}{Identity matrix on~$\R^{n \times n}$}%
\nomenclature[Nf]{$e_k$}{Standard coordinate vector of~$\R^n$ ($k$-th column of~$I_n$), with~$1 \le k \le n$}%
\nomenclature[Ng]{$\mathcal{O}(\cdot)$}{Big-O notation}%
\nomenclature[Nh]{$o(\cdot)$}{Little-O notation}%
\nomenclature[Oa]{$[\cdot]_{+}$}{Elementwise positive-part operator}%
\nomenclature[Ob]{$[\cdot]_{-}$}{Elementwise negative-part operator}%
\nomenclature[Oc]{$\abs{\cdot}$}{Elementwise modulus operator}%
\nomenclature[Od]{$\inner{\cdot, \cdot}$}{Inner-product operator (may be subscripted for sake of clarity)}%
\nomenclature[Oe]{$\norm{\cdot}$}{Norm of a vector or a matrix (may be subscripted for sake of clarity)}%
\nomenclature[Of]{$\nabla$}{Gradient operator (elements~$\partial / \partial x_i$, with~$i \in \set{1, 2, \dots, n}$)}%
\nomenclature[Og]{$\nabla^2$}{Hessian operator (elements~$\partial^2 / \partial x_i \partial x_j$, with~$i, j \in \set{1, 2, \dots, n}$)}%
\nomenclature[Oh]{$\land$}{Logic and operator}%
\nomenclature[Sa]{$\emptyset$}{Empty set}%
\nomenclature[Sb]{$[a, b]$}{Closed set~$\set{x \in \R : a \le x \le b}$ with~$a \le b$}%
\nomenclature[Sc]{$(a, b)$}{Open set~$\set{x \in \R : a < x < b}$ with~$a < b$}%
\nomenclature[Sd]{$[a, b)$}{Semi-open set~$\set{x \in \R : a \le x < b}$ with~$a < b$}%
\nomenclature[Se]{$(a, b]$}{Semi-open set~$\set{x \in \R : a < x \le b}$ with~$a < b$}%
\nomenclature[Sf]{$\R$}{Set of real numbers}%
\nomenclature[Sg]{$\R^n$}{Real coordinate space of dimension~$n$}%
\nomenclature[Sh]{$\R^{m \times n}$}{Real matrix space of dimension~$m \times n$}%
\nomenclature[Si]{$\Omega$}{Feasible set, included in~$\R^n$}%
\nomenclature[Sj]{$\ieq$}{Set of indices of the equality constraints}%
\nomenclature[Sk]{$\iub$}{Set of indices of the inequality constraints}%
\todo[noline]{Replace the nomenclature items.}

\section{Overview of \glsfmtlong{dfo}}

Optimization is the study of extremal points and values of mathematical functions.
Traditional optimization aims at minimizing (or maximizing) a real-valued function~$\obj$, referred to as the \emph{objective function}, within a given set of points~$\Omega \subseteq \R^n$, referred to as the \emph{feasible set}.
It is well known that essential information to optimization is embraced in the (possibly generalized) derivatives of the functions involved.
However, such derivatives may not exist.
Even if they are well defined, practical evaluations of them may be unavailable, unreliable, or prohibitively expensive.
This thesis focuses on this class of problems, referred to as \gls{dfo}~\cite{Conn_Scheinberg_Vicente_2009b,Audet_Hare_2017,Custodio_Scheinberg_Vicente_2017,Larson_Menickelly_Wild_2019}.

\Gls{dfo} problems arise naturally when the objective function or the feasible set results from complex experiments or simulations.
Regarding these functions as black-boxes, people often refer to those problems as \gls{bbo} problems.
We emphasize that we are \emph{not} investigating nonsmooth optimization\todo{Put two classical references (Clark and ?).}, which studies problems that involve nonsmooth functions.
In \gls{dfo}, classical or generalized derivatives may be well defined, but cannot be numerically assessed.

\Gls{dfo} methods use only function values to solve optimization problems.
Therefore, the leading complexity measure we consider is the number of function evaluations.
In practice, each function evaluation may require several minutes or even several days to complete\todo{Refer to the section in a book that talks about this.}.
For instance, a recent application of \gls{dfo} is hyperparameter tuning in machine learning~\cite{Ghanbari_Scheinberg_2017}, for which one objective function evaluation necessitates training a machine learning model (see~\cref{subsec:machine-learning}).
Hence, in \gls{dfo} methods, the expense of numerical linear algebra is less of a concern, although we will maintain it acceptable.

In this introduction, we consider the nonlinearly-constrained problem
\begin{subequations}
    \label{eq:nlcp-intro}
    \begin{align}
        \min        & \quad \obj(x)\\
        \text{s.t.} & \quad \con{i}(x) \le 0, ~ i \in \iub, \label{eq:nlcp-intro-cub}\\
                    & \quad \con{i}(x) = 0, ~ i \in \ieq, \label{eq:nlcp-intro-ceq}\\
                    & \quad x \in \R^n, \nonumber
    \end{align}
\end{subequations}
where the \emph{objective} and \emph{constraint functions}~$\obj$ and~$\con{i}$, with~$i \in \iub \cup \ieq$, are real-valued functions on~$\R^n$, and where the sets of indices~$\iub$ and~$\ieq$ are finite (perhaps empty) and disjoint.
The feasible set of this problem is\todo{Check the mathrel}
\begin{equation*}
    \Omega \eqdef \set{x \in \R^n \mathrel{:} \con{i}(x) \le 0 ~ \text{for~$i \in \iub$}, ~ \con{i}(x) = 0 ~ \text{for~$i \in \ieq$}}.
\end{equation*}

We emphasize that~\cref{eq:nlcp-intro-cub,eq:nlcp-intro-ceq} may include bound constraints.
We do not extract them explicitly in this chapter, but they may need to be handled differently from other constraints, because they often represent inalienable physical or theoretical restrictions.
We will take this into consideration in our development\todo{Find a better word.} (see~\cref{ch:cobyqa-intro}).

\section{Examples of applications}

\subsection{Automatic error analysis}

A typical example of \gls{dfo} applications is automatic error analysis~\cite{Higham_1993,Higham_2002}, which formulates numerical computation's accuracies and stabilities using optimization problems.
Consider, for instance, the Gaussian elimination with partial pivoting of a matrix~$A \in \R^{n \times n}$, given in~\cref{alg:gepp}.

\begin{algorithm}[ht]
    \caption{Gaussian elimination with partial pivoting}
    \label{alg:gepp}
    \DontPrintSemicolon
    \KwData{Matrix~$A \in \R^{n \times n}$.}
    Initialize $A^{(0)} \gets A$\;
    \For{$k = 1, 2, \dots, n - 1$}{
        Determine the pivot index~$j = \argmax \set[\big]{\abs[\big]{A_{i, k}^{(k - 1)}} : k \le i \le n}$\;
        \eIf{$A_{j, k}^{(k - 1)} \neq 0$}{
            Exchange the~$k$th and the~$j$th rows of~$A^{(k - 1)}$\;
            Evaluate the multiplier~$\tau^k \in \R^n$ with components
            \begin{algoempheq}[left={\tau_i^k = \empheqlbrace}]{alignat*=2}
                & A_{i, k}^{(k - 1)} / A_{k, k}^{(k - 1)}   && \quad \text{if~$i > k$, and}\\
                & 0                                         && \quad \text{otherwise}
            \end{algoempheq}
            Update~$A^{(k)} \gets (I_n - \tau^k e_k^{\T})A^{(k - 1)}$\;
        }{
            Set~$A^{(k)} \gets A^{(k - 1)}$\;
        }
    }
\end{algorithm}

\Citeauthor{Wilkinson_1963}'s backward error analysis (see, e.g., equation~(25.14) of chapter~3 in~\cite{Wilkinson_1963}, where~$t$ is introduced at the beginning of paragraph~10, and~$g$ at the end of page~97) demonstrates that the growth factor of the Gaussian elimination, defined by
\begin{equation}
    \label{eq:gepp-growth-factor}
    \rho_n(A) \eqdef \frac{\max_{0 \le k \le n - 1} \norm{A^{(k)}}_{\max}}{\norm{A}_{\max}},
\end{equation}
determinates the numerical stability of~\cref{alg:gepp}, where~$\norm{\cdot}_{\max}$ denotes the max norm of a matrix, i.e., the largest absolute value of the matrix's entries.
More specifically, the~$\ell_{\infty}$-norm of the backward error of the computed solution is bounded from above by a term proportional to~$\rho_n(A)$.
To study the worst-case scenario of~\cref{alg:gepp}, we wish to determine how large~$\rho_n$ can be and hence, to solve
\begin{equation}
    \label{eq:gepp-opti}
    \max_{A \in \R^{n \times n}} \rho_n(A).
\end{equation}
Note that~$\R^{n \times n}$ is isomorphic to~$\R^{n^2}$ and hence, problem~\cref{eq:gepp-opti} can straightforwardly be formulated as problem~\cref{eq:nlcp-intro}.
Besides, although the growth factor is defined everywhere, it may not be continuous at the points yielding a tie in the selection of the pivot element.
Moreover, it is not differentiable at the points yielding a tie in any maximum operator in equation~\cref{eq:gepp-growth-factor}.
Hence, optimization methods based on derivative information cannot be used for this problem.
In such a case, \gls{dfo} methods can help solving problem~\cref{eq:gepp-opti}.
Note that the optimal value and all optimal solutions to problem~\cref{eq:gepp-opti} are analytically known~\cite{Higham_Higham_1989}, but \gls{dfo} methods can be used to help the theoretical development~\cite{Higham_1993}.

\subsection{Tuning nonlinear optimization methods}

Another well-known example of \gls{dfo} applications is the parameter tuning of nonlinear optimization methods~\cite{Audet_Orban_2006}.
For example, consider~\cref{alg:trust-region}, a basic trust-region method for solving problem~\cref{eq:nlcp-intro} when~$\iub = \ieq = \emptyset$.

\begin{algorithm}[ht]
    \caption{Basic trust-region method for unconstrained optimization}
    \label{alg:trust-region}
    \DontPrintSemicolon
    \KwData{Objective function~$\obj$, initial guess~$x^0 \in \R^n$, initial trust-region radius~$\Delta_0 > 0$, and parameters~$0 < \eta_1 \le \eta_2 < 1$ and~$0 < \theta_1 < 1 < \theta_2$.}
    \For{$k = 0, 1, \dots$}{
        Define a simple function~$m_k$ such that~$m_k(d) \approx f(x^k + d)$ for~$\norm{d} \le \Delta_k$\;
        Set the trial step~$d^k$ to an approximate solution to
        \begin{algomathdisplay}
            \begin{aligned}
                \min        & \quad m_k(d)\\
                \text{s.t.} & \quad \norm{d} \le \Delta_k,\\
                            & \quad d \in \R^n
            \end{aligned}
        \end{algomathdisplay}
        Evaluate the trust-region ratio
        \begin{algomathdisplay}
            \rho_k \gets \frac{\obj(x^k) - \obj(x^k + d^k)}{m_k(0) - m_k(d^k)}
        \end{algomathdisplay}
        \eIf{$\rho_k \ge \eta_1$}{ \nllabel{alg:trust-region-success}
            Update the trial point~$x^{k + 1} \gets x^k + d^k$\;
        }{
            Retain the trial point~$x^{k + 1} \gets x^k$\;
        }
        Update the trust-region radius
        \begin{algoempheq}[left={\Delta_{k + 1} \gets \empheqlbrace}]{alignat*=2}
            & \theta_1 \Delta_k && \quad \text{if~$\rho_k \le \eta_1$,}\\
            & \Delta_k          && \quad \text{if~$\eta_1 < \rho_k \le \eta_2$, and}\\
            & \theta_2 \Delta_k && \quad \text{otherwise}
        \end{algoempheq}
    }
\end{algorithm}

The most important simplification in~\cref{alg:trust-region} lies in~\cref{alg:trust-region-success}.
A complete framework includes a parameter~$\eta_0 \ge 0$ satisfying~$\eta_0 \le \eta_1$, and the condition in~\cref{alg:trust-region-success} is replaced by~$\rho_k \ge \eta_0$.
In practice, we usually have~$\eta_0 = 0$.
However, this parameter genuinely complexifies the theoretical analysis of the trust-region method, and hence, we omit it here for sake of simplicity.
We consider only the four parameters~$\eta_1$,~$\eta_2$,~$\theta_1$, and~$\theta_2$.
To choose those parameters, we minimize some measure of the method's expense (e.g., the \glsxtrshort{cpu} time to solve a given set of optimization problems),~$C$ say.
In other words, we wish to solve the optimization problem
\begin{subequations}
    \label{eq:tuning-opti}
    \begin{align}
        \min        & \quad C(\eta_1, \eta_2, \theta_1, \theta_2)\\
        \text{s.t.} & \quad 0 \le \eta_1 \le \eta_2 < 1,\\
                    & \quad 0 < \theta_1 < 1 < \theta_2.
    \end{align}
\end{subequations}
Derivatives of~$C$ cannot be evaluated if they even exist.
Such a problem is then solved using \gls{dfo} methods, for example using the \gls{mads} method~\cite{Audet_Orban_2006}.
\Citeauthor{Audet_Digabel_Tribes_2019} modified the \gls{mads} method to solve problem~\cref{eq:tuning-opti} with a controlled number of significant digits~\cite{Audet_Digabel_Tribes_2019}, to determine parameters that can be used by practitioners.
Interestingly, \gls{dfo} methods can be self-tuned using the method presented above.
The \gls{bfo} solver~\cite{Porcelli_Toint_2017}, a method for bound-constrained problems mixing continuous and discrete variables, is an example of self-tuned \gls{dfo} methods.

\subsection{Hyperparameter tuning in machine learning}
\label{subsec:machine-learning}

A more recent example of \gls{dfo} applications is hyperparameter tuning in machine learning~\cite{Ghanbari_Scheinberg_2017}.
For instance, Google solves hyperparameter tuning problems using Google Vizier~\cite{Golovin_Etal_2017}, the Google-internal service for performing black-box optimization.
To illustrate this example, we consider the following hyperparameter tuning problem of a \gls{svm} for binary classification.
Given a binary-labeled dataset~$\set{(x_i, y_i)}_{i = 1, 2, \dots, m} \subseteq \R^n \times \set{\pm 1}$, we build a \gls{svm} to classify the data with their respective labels.
A binary classification is obtained using a~$C$-\gls{svc}~\cite{Chang_Lin_2011} by solving the optimization problem
\begin{subequations}
    \label{eq:csvc}
    \begin{align}
        \min        & \quad \frac{1}{2} \norm{\omega}_2^2 + C \norm{\xi}_1\\
        \text{s.t.} & \quad y_i (\beta + \inner{\omega, \varphi_{\gamma}(x_i)}) \ge 1 - \xi_i, ~ i \in \set{1, 2, \dots, m},\\
                    & \quad \xi \ge 0,\\
                    & \quad (\omega, \beta, \xi) \in \R^{\ell} \times \R \times \R^m,
    \end{align}
\end{subequations}
where~$\varphi_{\gamma}$ is a function mapping the data to a higher-dimensional space~$\R^{\ell}$ and~$\gamma > 0$ and~$C > 0$ are parameters.
Given a solution~$(\omega^{\ast}, \beta^{\ast}, \xi^{\ast}) \in \R^{\ell} \times \R \times \R^m$ to problem~\cref{eq:csvc}, the~$C$-\gls{svc} classifies any data~$x \in \R^n$ according to
\begin{equation}
    \label{eq:csvc-classifier}
    \delta(x) \eqdef \sgn(\beta^{\ast} + \inner{\omega^{\ast}, \varphi_{\gamma}(x)}),
\end{equation}
which maps an observation~$x \in \R^n$ to a label in~$\set{\pm 1}$.
It is clear that~$\delta$ depends on the two parameters~$C$ and~$\gamma$, which can be chosen by solving an optimization problem.
The objective function~$P$ of this problem is a~$5$-fold cross-validation based on some performance measure of the model~\cref{eq:csvc-classifier}.
The general~$k$-fold cross-validation to define~$P(C, \gamma)$ is presented in~\cref{alg:cross-validation}.

\begin{algorithm}[ht]
    \caption{$k$-fold cross-validation of an \glsfmtshort{svc} with parameters~$C$ and~$\gamma$}
    \label{alg:cross-validation}
    \DontPrintSemicolon
    \KwData{Labeled dataset~$\set{(x_i, y_i)}_{i = 1, 2, \dots, m} \subseteq \R^n \times \set{\pm 1}$ and fold number~$k > 0$.}
    Split the dataset into~$k$ balanced groups\;
    \For{$i = 1, 2, \dots, k$}{
        Calculate~$(\omega^{\ast}, \beta^{\ast}, \xi^{\ast})$ with the all the data except those in the~$i$th group\;
        Evaluate the performance~$p_i$ of the model~\cref{eq:csvc-classifier} on the data in the~$i$th group\;
    }
    Define~$P(C, \gamma)$ by summarizing the performances~$\set{p_1, p_2, \dots, p_k}$\;
\end{algorithm}

A typical example of model's performance used in the~$k$-fold cross-validation is the model's accuracy, i.e., the percentage of data correctly classified.
The~\gls{auc}~\cite{Hanley_Mcneil_1982} is another example of performance measure, particularly effective for imbalanced datasets~\cite{Bradley_1997}.
The hyperparameter tuning problem can be formulated as
\begin{equation*}
    \begin{aligned}
        \min        & \quad P(C, \gamma)\\
        \text{s.t.} & \quad C > 0,\\
                    & \quad \gamma > 0.
    \end{aligned}
\end{equation*}
It is clear that derivatives of the objective function of such a problem cannot be easily evaluated and may even not exist.
This problem may be solved using \gls{dfo} methods.

As in~\cite{Qian_Yu_2021}, \gls{dfo} be also be applied to reinforcement learning.
Instead of training a model on a fixed labelled dataset, reinforcement learning bases the training process on rewarding expected behaviors and punishing undesired ones.
Hence, it often consists in finding optimal parameters that maximize a reward.
However, this reward's derivatives often cannot be evaluated, and \gls{dfo} methods can be an approach to solving such problems.

\subsection{Some industrial and engineering applications}

\todo[noline]{Rewrite everything, put the citations first, then introduce MDO.}

\todo[noline]{Check applications from Wild, Caris, Larsen, Shoemaker, Rinaldi, Vicente, Gratton, Royer, Stephano, Lucidi, Scheinberg, Custodio (such as GAN).}

\todo[noline]{Mention that our work in included in a MDO software.}

There are many other applications of \gls{dfo} in industry and engineering, such as in helicopter rotor blade design~\cite{Booker_Etal_1998a,Booker_Etal_1998b,Serafini_1998}, groundwater supply and bioremediation engineering~\cite{Fowler_Etal_2008,Mugunthan_Shoemaker_Regis_2005,Yoon_Shoemaker_1999}, aeroacoustic shape design~\cite{Marsden_2004,Marsden_Etal_2004}, hydrodynamic design~\cite{Duvigneau_Visonneau_2004}, nuclear energy density optimization~\cite{Kortelainen_Etal_2010}\todo{Add the 2 other papers.}, reservoir engineering and engine calibration~\cite{Langouet_2011}, and analog circuit design~\cite{Latorre_Etal_2019} for instance.
This problems often involve sophisticated models...

In industry and engineering, \gls{mdo} designates a field that uses optimization methods for solving design problems that involve several disciplines.
For example, the objective and constraint functions of a \gls{mdo} problem can be defined by different departments of the same company, or even by different companies, such as in aircraft engine engineering~\cite{Gazaix_Etal_2019}.

\section{Optimality conditions for smooth optimization}

We discuss in this section necessary and sufficient conditions for optimality.
We do not assume any structure on the objective and constraint functions, except some smoothness.
More specialized results can be obtained by assuming that problem~\cref{eq:nlcp-intro} is convex for example, but it is out of the scope of this work.

\subsection{Local and global solutions}

Before solving problem~\cref{eq:nlcp-intro}, we must define what a solution is.
The most natural definition of a solution\todo{Rewrite to avoid definition and solution} is given in~\cref{def:global-solution}.

\begin{definition}[Global solution]
    \label{def:global-solution}
    To problem~\cref{eq:nlcp-intro}, a point~$x^{\ast} \in \R^n$ is a \emph{global solution} if~$x^{\ast} \in \Omega$ and~$\obj(x) \ge \obj(x^{\ast})$ for all~$x \in \Omega$.
\end{definition}

\todo[noline]{Be clear that local minimum is easier than global ones.}

\todo[noline]{Emphasize that convexity does not make problems easier.}
% https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1011.7837&rep=rep1&type=pdf

However, it is known that finding a global solution is NP-hard without any convexity assumption on problem~\cref{eq:nlcp-intro}, even in gradient-based settings.
% http://www-personal.umich.edu/~murty/np.pdf
Consider for example the following problem\todo{Remove the formulation, give some cited examples.}, known to be NP-complete.

\begin{problem}[Subset sum]
    \label{pb:subset-sum}
    Given a finite set of scalars,~$\set{\alpha_1, \alpha_2, \dots, \alpha_n} \subseteq \R$ say, is there any nonempty subset whose sum is zero?
\end{problem}

It is clear that~\cref{pb:subset-sum} can be formulated as the optimization problem
\begin{equation*}
    \begin{aligned}
        \min        & \quad \bigg( \sum_{i = 1}^n \alpha_i x_i \bigg)^2 + \sum_{i = 1}^n x_i^2 (1 - x_i)^2\\
        \text{s.t.} & \quad x \in \R^n,
    \end{aligned}
\end{equation*}
since its global solution is zero if and only if there exists a nonempty subset whose sum is zero.
Therefore, we relax the definition of solution to problem~\cref{eq:nlcp-intro} in~\cref{def:local-solution}.

\begin{definition}[Local solution]
    \label{def:local-solution}
    To problem~\cref{eq:nlcp-intro}, a point~$x^{\ast} \in \R^n$ is
    \begin{itemize}
        \item a \emph{local solution} if~$x^{\ast} \in \Omega$ and there exists a neighborhood~$\mathcal{N} \subseteq \R^n$ of~$x^{\ast}$ such that~$\obj(x) \ge \obj(x^{\ast})$ for all~$x \in \mathcal{N} \cap \Omega$,
        \item a \emph{strict local solution} if~$x^{\ast} \in \Omega$ and there exists a neighborhood~$\mathcal{N} \subseteq \R^n$ of~$x^{\ast}$ such that~$\obj(x) > \obj(x^{\ast})$ for all~$x \in \mathcal{N} \cap \Omega \setminus \set{x^{\ast}}$, and
        \item an \emph{isolated local solution} if there exists a neighborhood~$\mathcal{N} \subseteq \R^n$ of~$x^{\ast}$ such that it is the only local solution in~$\mathcal{N} \cap \Omega$.
    \end{itemize}
\end{definition}

Note that an isolated local solution is strict, but the converse is not true.
From now on, we refer to as an \emph{optimal solution} to problem~\cref{eq:nlcp-intro} a local solution, since we do not study global optimization.
The value of the objective function~$\obj$ at an optimal solution is referred to as the \emph{optimal value}.

\subsection{Constraint qualifications}

Before introducing any necessary and sufficient conditions for local optimality, we discuss some regularity conditions on the constraints~\cref{eq:nlcp-intro-cub,eq:nlcp-intro-ceq}, referred to as the \emph{constraint qualifications}.
These assumptions will be required for the necessary and sufficient conditions to hold.
We first introduce the notion of \emph{active set}.

\begin{definition}[Active set]
    The \emph{active set}~$\mathcal{A}(x) \subseteq \iub \cup \ieq$ for problem~\cref{eq:nlcp-intro} at a point~$x \in \Omega$ is defined by
    \begin{equation*}
        \mathcal{A}(x) \eqdef \ieq \cup \set{i \in \iub : \con{i}(x) \ge 0}.
    \end{equation*}
\end{definition}

If a constraint belong to the active set at a given point, it is said to be \emph{active} at this point, and \emph{inactive} otherwise.

\begin{definition}[Constraint qualification]
    Given~$x \in \Omega$, denote~$\mathcal{A}(x)$ the active set for problem~\cref{eq:nlcp-intro} at~$x$, and assume that the constraint functions~$\con{i}$ are differentiable at~$x$ for all~$i \in \mathcal{A}(x)$.
    We say that
    \begin{itemize}
        \item the \gls{licq} holds at~$x$ if the gradients~$\nabla \con{i}(x)$ are linearly independent for all~$i \in \mathcal{A}(x)$, and
        \item the \gls{mfcq} holds at~$x$ if the gradients~$\nabla \con{i}(x)$ are linearly independent for all~$i \in \ieq$ and there exists a vector~$z \in \R^n$ such that
        \begin{empheq}[left=\empheqlbrace]{alignat*=2}
            & \inner{\nabla \con{i}(x), z} < 0  && \quad \text{if~$i \in \mathcal{A}(x) \cap \iub$, and}\\
            & \inner{\nabla \con{i}(x), z} = 0  && \quad \text{if~$i \in \ieq$}.
        \end{empheq}
    \end{itemize}
\end{definition}

\begin{itemize}
    \item \gls{acq}.
    \item \gls{gcq}.
    \item \gls{lcq}.
    \item \gls{crcq}.
    \item \gls{cpld}.
    \item \gls{qncq}.
    \item \gls{sc}.
\end{itemize}

\subsection{First-order optimality conditions}

\subsubsection{Statement of the optimality conditions}

\begin{equation*}
    \lag(x, \lambda) \eqdef \obj(x) + \sum_{\mathclap{i \in \iub \cup \ieq}} \lambda_i \con{i}(x),
\end{equation*}
where~$\lambda = (\lambda_i)_{i \in \iub \cup \ieq}$ with~$\lambda_i \in \R$ for all~$i \in \iub \cup \ieq$.

\begin{theorem}[First-order necessary conditions~\cite{Nocedal_Wright_2006}] % Theorem 12.1
    \label{thm:fonc}
    Let~$x^{\ast} \in \Omega$ be a local solution to problem~\cref{eq:nlcp-intro}, assume that the functions~$\obj$ and~$\con{i}$, for all~$i \in \iub \cup \ieq$, are continuously differentiable in a neighborhood of~$x^{\ast}$, and that \gls{licq} holds at~$x^{\ast}$.
    Then there exists a Lagrange multiplier~$\lambda^{\ast} = (\lambda_i^{\ast})_{i \in \iub \cup \ieq}$ with~$\lambda_i^{\ast} \in \R$ for all~$i \in \iub \cup \ieq$ such that
    \begin{subequations}
        \label{eq:kkt-intro}
        \begin{empheq}[left=\empheqlbrace]{alignat=2}
            & \nabla_x \lag(x^{\ast}, \lambda^{\ast}) = 0,  && \label{eq:kkt-intro-sta}\\
            & \con{i}(x^{\ast}) \le 0,                      && \quad \text{if~$i \in \iub$,} \label{eq:kkt-intro-pfub}\\
            & \con{i}(x^{\ast}) = 0,                        && \quad \text{if~$i \in \ieq$,} \label{eq:kkt-intro-pfeq}\\
            & \lambda_i^{\ast} \con{i}(x^{\ast}) = 0,       && \quad \text{if~$i \in \iub$,} \label{eq:kkt-intro-csl}\\
            & \lambda_i^{\ast} \ge 0,                       && \quad \text{if~$i \in \iub$.} \label{eq:kkt-intro-df}
        \end{empheq}
    \end{subequations}
\end{theorem}

The conditions~\cref{eq:kkt-intro} are commonly referred to as the \gls{kkt} conditions~\cite{Karush_1939,Kuhn_Tucker_1951}.
More specifically, condition~\cref{eq:kkt-intro-sta} is referred to as the \emph{stationarity} condition, conditions~\cref{eq:kkt-intro-pfub,eq:kkt-intro-pfeq} as the \emph{primal feasibility} conditions, condition~\cref{eq:kkt-intro-csl} as the \emph{complementary slackness} condition, and condition~\cref{eq:kkt-intro-df} as the \emph{dual feasibility} condition.
Note that this theorem holds for more general constraint qualifications, such as the \gls{mfcq} (see, e.g.,~\cite[p.~339]{Nocedal_Wright_2006}).
% Moreover, the smoozthness assumptions on the objective and constraint functions can be relaxed, using generalized derivatives.

\subsubsection{Graphical insight of the first-order optimality conditions}

% We will not give the proof but show it on a simple example
To help to understand graphically~\cref{thm:fonc}, we consider the problem
\begin{subequations}
    \label{eq:kkt-description}
    \begin{align}
        \min        & \quad \obj(x) = x_1 + x_2\\
        \text{s.t.} & \quad \con{1}(x) = x_1^2 + x_2^2 - 2 \le 0, \label{eq:kkt-description-c1}\\
                    & \quad \con{2}(x) = -x_2 \le 0, \label{eq:kkt-description-c2}\\
                    & \quad x \in \R^2, \nonumber
    \end{align}
\end{subequations}
whose solution is~$x^{\ast} = (-\sqrt{2}, 0)$.
A graphical representation of problem~\cref{eq:kkt-description} is given in~\cref{fig:kkt-description}, where the white area represents the feasible set.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}
        \begin{axis}[%
            xmin=-5,%
            xmax=2,%
            ymin=-2,%
            ymax=2,%
            axis equal image,%
            xlabel={$x_1$},%
            ylabel={$x_2$},%
            axis background/.style={%
                pattern=north west lines,%
                pattern color=black!20,%
                even odd rule,%
                insert path={let \p1=(axis cs:0,0), \p2=(axis cs:2^0.5,0), \n1={veclen(\x2-\x1,\y2-\y1)}, in (\p2) arc(0:180:\n1) -- cycle},%
            },%
        ]
            \draw[dashed] (0,0) circle[radius=2^0.5];
            \draw[dashed] (-5,0) -- (2,0);
            \draw[-latex] (-2^0.5,0) -- (-3*2^0.5,0) node[above right] {$\nabla \con{1}(x^{\ast})$};
            \draw[-latex] (-2^0.5,0) -- (-2^0.5,-1) node[below left] {$\nabla \con{2}(x^{\ast})$};
            \draw[-latex] (-2^0.5,0) -- (1-2^0.5,1) node[below right] {$\nabla \obj(x^{\ast})$};
            \addplot[BrickRed,mark=*,only marks] coordinates {(-2^0.5,0)};
            \node[above left] at (-2^0.5,0) {$x^{\ast}$};
        \end{axis}
    \end{tikzpicture}
    \caption{Graphical representation of problem~\cref{eq:kkt-description}}
    \label{fig:kkt-description}
\end{figure}

\todo[noline]{Find a solution to make the proof logic}

Assume that we are given~$x \in \R^2$ satisfying the constraints~\cref{eq:kkt-description-c1,eq:kkt-description-c2} that is not optimal.
We then have a direction~$d \in \R^2$ such that~$x + d$ satisfies the constraints~\cref{eq:kkt-description-c1,eq:kkt-description-c2} and~$\obj(x + d) < \obj(x)$.
Therefore,
\begin{subequations}
    \label{eq:kkt-description-system}
    \begin{empheq}[left=\empheqlbrace]{alignat=1}
        & 0 > \obj(x + d) - \obj(x) = \inner{\nabla \obj(x), d},\\
        & 0 \ge \con{1}(x + d) \approx \con{1}(x) + \inner{\nabla \con{1}(x), d}, \label{eq:kkt-description-system-c1}\\
        & 0 \ge \con{2}(x + d) = \con{2}(x) + \inner{\nabla \con{2}(x), d}.
    \end{empheq}
\end{subequations}
If a constraint is not active at~$x$, then such a direction~$d$ can be chosen so that this constraint is also inactive at~$x + d$.
Let us therefore assume that~$\con{1}(x) = \con{2}(x) = 0$.
By omitting the approximation in~\cref{eq:kkt-description-system-c1}, we then have
\begin{subequations}
    \label{eq:kkt-proof}
    \begin{empheq}[left=\empheqlbrace]{alignat=1}
        & \inner{\nabla \obj(x), d} < 0,\\
        & \inner{\nabla \con{1}(x), d} \le 0,\\
        & \inner{\nabla \con{2}(x), d} \le 0.
    \end{empheq}
\end{subequations}
We see on~\cref{fig:kkt-description} that no such direction exists for~$x = x^{\ast}$.
One can straightforwarly\todo{Cite the Farkas' lemma} show that no vector~$d$ satisfy system~\cref{eq:kkt-proof} only when there exists a Lagrange multiplier~$\lambda = (\lambda_i)_{i \in \iub \cup \ieq}$ with~$\lambda_i \ge 0$ for all~$i \in \iub \cup \ieq$ such that~$\nabla_x \lag(x, \lambda) = 0$, since
\begin{equation*}
    \nabla_x \lag(x, \lambda) = \nabla \obj(x) + \sum_{\mathclap{i \in \iub \cup \ieq}} \lambda_i \nabla \con{i}(x).
\end{equation*}
A formal proof of~\cref{thm:fonc} follows the scheme presented above, by bounding the error terms arising in the first-order approximation~\cref{eq:kkt-description-system}.

\subsection{Second-order optimality conditions}

\begin{theorem}[Second-order necessary conditions~\cite{Nocedal_Wright_2006}] % Theorem 12.5
    Let~$x^{\ast} \in \Omega$ be a local solution to problem~\cref{eq:nlcp-intro}, assume that the functions~$\obj$ and~$\con{i}$, for all~$i \in \iub \cup \ieq$, are twice continuously differentiable in a neighborhood or~$x^{\ast}$, and that \gls{licq} holds at~$x^{\ast}$.
    Denote~$\mathcal{A}(x^{\ast})$ the active set for problem~\cref{eq:nlcp-intro} at~$x^{\ast}$.
    Let~$\lambda^{\ast} = (\lambda_i^{\ast})_{i \in \iub \cup \ieq}$ with~$\lambda_i^{\ast} \in \R$ for all~$i \in \iub \cup \ieq$ be a Lagrange multiplier satisfying the KKT condition~\cref{eq:kkt-intro}, and let~$z \in \R^n$ be any vector such that
    \begin{subequations}
        \label{eq:second-order-intro}
        \begin{empheq}[left=\empheqlbrace]{alignat=2}
            & \inner{\nabla \con{i}(x^{\ast}), z} = 0,      && \quad \text{if~$i \in \ieq$,}\\
            & \inner{\nabla \con{i}(x^{\ast}), z} = 0,      && \quad \text{if~$i \in \mathcal{A}(x^{\ast}) \cap \iub$ and~$\lambda_i^{\ast} > 0$, and}\\
            & \inner{\nabla \con{i}(x^{\ast}), z} \ge 0,    && \quad \text{if~$i \in \mathcal{A}(x^{\ast}) \cap \iub$ and~$\lambda_i^{\ast} = 0$.}
        \end{empheq}
    \end{subequations}
    Then~$\inner{z, \nabla_{x, x}^2 \lag(x^{\ast}, \lambda^{\ast}) z} \ge 0$.
\end{theorem}

\begin{theorem}[Second-order sufficient conditions~\cite{Nocedal_Wright_2006}] % Theorem 12.6
    Let~$x^{\ast} \in \Omega$ be a given point, and assume that the functions~$\obj$ and~$\con{i}$, for all~$i \in \iub \cup \ieq$, are twice continuously differentiable in a neighborhood of~$x^{\ast}$, that \gls{licq} holds at~$x^{\ast}$, and that there exists a Lagrange multiplier~$\lambda^{\ast} = (\lambda_i^{\ast})_{i \in \iub \cup \ieq}$ with~$\lambda_i^{\ast} \in \R$ for all~$i \in \iub \cup \ieq$ satisfying the KKT condition~\cref{eq:kkt-intro}.
    If for all nonzero vector~$z \in \R^n \setminus \set{0}$ satisfying the conditions~\cref{eq:second-order-intro} we have~$\inner{z, \nabla_{x, x}^2 \lag(x^{\ast}, \lambda^{\ast}) z} > 0$, then~$x^{\ast}$ is a strict local solution to problem~\cref{eq:nlcp-intro}.
\end{theorem}

\section{Methodology of \glsfmtlong{dfo} algorithms}

\subsection{Frameworks and algorithms for \glsfmtlong{dfo}}

\begin{itemize}
    \item Direct-search and model-based methods.
    \item Line-search and trust-region methods.
    \item Filter methods and hybrid methods.
    \item implicit filtering methods (hybrid between direct-search and line-search).
\end{itemize}

\subsection{Examples of \glsfmtlong{dfo} methods}

\begin{itemize}
    \item The earliest work on numerical \gls{dfo} is attributed to~\citeauthor{Fermi_Metropolis_1952}~\cite{Fermi_Metropolis_1952}, who developed a nonlinear least-squares solver using a \gls{dfo} coordinate search on MANIAC, an early computer based on the von Neumann architecture.
    \item Nelder-Mead method~\cite{Nelder_Mead_1965}.
    \item BFO~\cite{Porcelli_Toint_2017}.
    \item DFO~\cite{Conn_Scheinberg_Toint_1998}.
    \item NOMAD~\cite{Digabel_2011}.
    \item MNH~\cite{Wild_2008}
\end{itemize}

\section{Benchmarking tools for \glsfmtlong{dfo} methods}

\subsection{Performance profiles}

\subsection{Data profiles}
